{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\An-ck\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\An-ck\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\An-ck\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\An-ck\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\An-ck\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\An-ck\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "#%load_ext tensorboard\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow.keras.layers as layers\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from util import load_data, load_data_fashion, create_dataset\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = load_data(reshape=1)\n",
    "(f_x_train, f_y_train), (f_x_test, f_y_test) = load_data_fashion(reshape=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    # Fully-connected Variational Autoencoder\n",
    "    input_size = 28 * 28\n",
    "    inter_size = 64\n",
    "    latent_size = 2\n",
    "\n",
    "    inputs      = keras.Input(shape=(input_size,))\n",
    "    h           = layers.Dense(inter_size, activation='relu')(inputs)\n",
    "    z_mean      = layers.Dense(latent_size)(h)\n",
    "    z_log_sigma = layers.Dense(latent_size)(h)\n",
    "\n",
    "    # Function for sampling the latent feature space\n",
    "    def sampling(args):\n",
    "        z_mean, z_log_sigma = args\n",
    "        epsilon = K.random_normal(shape=(K.shape(z_mean)[0], latent_size),\n",
    "                                  mean=0., stddev=0.1)\n",
    "        return z_mean + K.exp(z_log_sigma) * epsilon\n",
    "\n",
    "    z = layers.Lambda(sampling)([z_mean, z_log_sigma])\n",
    "\n",
    "    # Create encoder\n",
    "    encoder = keras.Model(inputs, [z_mean, z_log_sigma, z], name='encoder')\n",
    "\n",
    "    # Create decoder\n",
    "    latent_inputs  = keras.Input(shape=(latent_size,), name='z_sampling')\n",
    "    x              = layers.Dense(inter_size, activation='relu')(latent_inputs)\n",
    "    outputs        = layers.Dense(input_size, activation='sigmoid')(x)\n",
    "    decoder = keras.Model(latent_inputs, outputs, name='decoder')\n",
    "\n",
    "    # instantiate VAE model\n",
    "    outputs = decoder(encoder(inputs)[2])\n",
    "    vae = keras.Model(inputs, outputs, name='vae_mlp')\n",
    "\n",
    "    # Loss\n",
    "    reconstruction_loss = keras.losses.binary_crossentropy(inputs, outputs)\n",
    "    reconstruction_loss *= input_size\n",
    "    kl_loss = 1 + z_log_sigma - K.square(z_mean) - K.exp(z_log_sigma)\n",
    "    kl_loss = K.sum(kl_loss, axis=-1)\n",
    "    kl_loss *= -0.5\n",
    "    vae_loss = K.mean(reconstruction_loss + kl_loss)\n",
    "    vae.add_loss(vae_loss)\n",
    "    vae.compile(optimizer='adam')\n",
    "    return vae\n",
    "\n",
    "def fit_model(model, x_train, y_train, x_test, y_test, normal=4, verbose=1, caseii=False, caseiii=False):\n",
    "    #logdir = os.path.join(\"logs\", str(normal)+\"_\"+datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "    #tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "    callbacks = [\n",
    "        keras.callbacks.EarlyStopping(patience=10)\n",
    "        #tensorboard_callback\n",
    "    ]\n",
    "    if caseii:\n",
    "        train = x_train[y_train!=normal]\n",
    "        test  = x_test[y_test!=normal]\n",
    "    if caseiii:\n",
    "        train = x_train\n",
    "        test  = x_test\n",
    "    else:\n",
    "        train = x_train[y_train==normal]\n",
    "        test  = x_test[y_test==normal]\n",
    "    \n",
    "    history = model.fit(train, train,\n",
    "                    epochs=100,\n",
    "                    batch_size=256,\n",
    "                    verbose=verbose,\n",
    "                    shuffle=True,\n",
    "                    validation_data=(test, test),\n",
    "                    callbacks=callbacks)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60.984375\n",
      "0.703125\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "start = time.process_time()\n",
    "\n",
    "model = fit_model(model, x_train, y_train, x_test, y_test, normal=4, verbose=0)\n",
    "\n",
    "end = time.process_time()\n",
    "print(end - start)\n",
    "\n",
    "start = time.process_time()\n",
    "xhat = model.predict(x_test)\n",
    "end = time.process_time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b55bf842815416da5b9d13a4ef0b626",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=30.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "95.54568607930976\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3466ad29efb40aa8cbc436615cd9c85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=30.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "99.83334053882143\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a938d29baf0e4907a6353588014811ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=30.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "87.81465289591243\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf09ee33eeb14127ae434d58a893ebc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=30.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "85.72742467795167\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff816712b2204315857bf87329967b76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=30.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "87.87840664751815\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e2711dfdf814f1c861fc0e16d9c03a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=30.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "91.25928322019179\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "560df6b31f81452e80e29a4995fc5dd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=30.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "95.89794347941265\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "117aa3b5ac0f4916bdfd3a317ba64362",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=30.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "93.65773699036576\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b914b37bc904c29a000d8cd12818c4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=30.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "79.54221135140358\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3ed7476f59f433d90b1b46d4a10953f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=30.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "92.01616989746053\n",
      "[95.14559143 99.84190662 88.52210422 85.76322537 87.78364972 90.78040839\n",
      " 96.029651   93.65173926 79.12487812 92.04149199]\n",
      "[1.04027055 0.02136071 1.18924201 1.01794828 0.72314154 0.62976151\n",
      " 0.34802407 0.80290864 0.69382041 0.2161652 ]\n"
     ]
    }
   ],
   "source": [
    "evals = np.zeros((10, 30))\n",
    "for i in range(10):\n",
    "    # Evaluate for all numbers\n",
    "    for j in tqdm_notebook(range(30)):\n",
    "        # Evaluate each method 30 times\n",
    "        model = create_model()\n",
    "        model = fit_model(model, x_train, y_train, x_test, y_test, normal=i, verbose=0)\n",
    "\n",
    "        x = np.copy( x_test )\n",
    "        y = y_test\n",
    "        labels = np.copy( y )\n",
    "        labels[ y == i ] = 0\n",
    "        labels[ y != i ] = 1\n",
    "        \n",
    "        xhat = model.predict(x)\n",
    "        \n",
    "        x = x.reshape(len(x), 28*28)\n",
    "        xhat = xhat.reshape(len(xhat), 28*28)\n",
    "        \n",
    "        err  = np.sum(np.abs(x-xhat), axis=1)\n",
    "        # Max-Min normalize the error\n",
    "        err /= np.max(err)\n",
    "        # Compute AUC\n",
    "        AUC = roc_auc_score(labels, err)\n",
    "        evals[i,j] = AUC\n",
    "    print(np.mean(evals[i,:])*100)\n",
    "\n",
    "print(np.mean(evals[:,:5], axis=1)*100)\n",
    "print(np.std(evals, axis=1)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CASE 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Epoch 1/100\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 251.4461 - val_loss: 192.0965\n",
      "Epoch 2/100\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 184.9021 - val_loss: 179.9899\n",
      "Epoch 3/100\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 177.4429 - val_loss: 173.6567\n",
      "Epoch 4/100\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 169.4552 - val_loss: 164.5482\n",
      "Epoch 5/100\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 163.7412 - val_loss: 161.4074\n",
      "Epoch 6/100\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 161.3670 - val_loss: 159.6579\n",
      "Epoch 7/100\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 159.7140 - val_loss: 158.2203\n",
      "Epoch 8/100\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 158.4698 - val_loss: 157.2250\n",
      "Epoch 9/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 157.4113 - val_loss: 156.3611\n",
      "Epoch 10/100\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 156.4066 - val_loss: 155.4299\n",
      "Epoch 11/100\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 155.5278 - val_loss: 154.6562\n",
      "Epoch 12/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 154.6802 - val_loss: 153.9048\n",
      "Epoch 13/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 153.9872 - val_loss: 153.2272\n",
      "Epoch 14/100\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 153.3186 - val_loss: 152.8474\n",
      "Epoch 15/100\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 152.7318 - val_loss: 152.2631\n",
      "Epoch 16/100\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 152.1736 - val_loss: 151.7106\n",
      "Epoch 17/100\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 151.6992 - val_loss: 151.3825\n",
      "Epoch 18/100\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 151.1912 - val_loss: 151.0624\n",
      "Epoch 19/100\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 150.7657 - val_loss: 150.5799\n",
      "Epoch 20/100\n",
      "212/212 [==============================] - 3s 14ms/step - loss: 150.4076 - val_loss: 150.2858\n",
      "Epoch 21/100\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 150.0688 - val_loss: 149.9151\n",
      "Epoch 22/100\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 149.6961 - val_loss: 149.5344\n",
      "Epoch 23/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 149.3915 - val_loss: 149.3011\n",
      "Epoch 24/100\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 149.1053 - val_loss: 149.0052\n",
      "Epoch 25/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 148.8086 - val_loss: 148.8510\n",
      "Epoch 26/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 148.5619 - val_loss: 148.5800\n",
      "Epoch 27/100\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 148.3292 - val_loss: 148.4651\n",
      "Epoch 28/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 148.1031 - val_loss: 148.1941\n",
      "Epoch 29/100\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 147.8694 - val_loss: 148.0445\n",
      "Epoch 30/100\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 147.7026 - val_loss: 147.8741\n",
      "Epoch 31/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 147.4922 - val_loss: 147.6973\n",
      "Epoch 32/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 147.3199 - val_loss: 147.5647\n",
      "Epoch 33/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 147.1819 - val_loss: 147.3575\n",
      "Epoch 34/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 146.9549 - val_loss: 147.3253\n",
      "Epoch 35/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 146.8352 - val_loss: 147.1851\n",
      "Epoch 36/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 146.6678 - val_loss: 147.0670\n",
      "Epoch 37/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 146.5590 - val_loss: 147.0085\n",
      "Epoch 38/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 146.4090 - val_loss: 146.8323\n",
      "Epoch 39/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 146.3092 - val_loss: 146.6656\n",
      "Epoch 40/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 146.1381 - val_loss: 146.5777\n",
      "Epoch 41/100\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 146.0152 - val_loss: 146.5835\n",
      "Epoch 42/100\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 145.8626 - val_loss: 146.3187\n",
      "Epoch 43/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 145.7806 - val_loss: 146.3018\n",
      "Epoch 44/100\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 145.6937 - val_loss: 146.2258\n",
      "Epoch 45/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 145.5630 - val_loss: 146.0759\n",
      "Epoch 46/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 145.4817 - val_loss: 146.0771\n",
      "Epoch 47/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 145.3593 - val_loss: 145.9997\n",
      "Epoch 48/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 145.2793 - val_loss: 145.8099\n",
      "Epoch 49/100\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 145.1946 - val_loss: 145.8498\n",
      "Epoch 50/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 145.0708 - val_loss: 145.7446\n",
      "Epoch 51/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 145.0196 - val_loss: 145.7633\n",
      "Epoch 52/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 144.8960 - val_loss: 145.6910\n",
      "Epoch 53/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 144.8031 - val_loss: 145.6486\n",
      "Epoch 54/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 144.7570 - val_loss: 145.5837\n",
      "Epoch 55/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 144.6932 - val_loss: 145.6186\n",
      "Epoch 56/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 144.6098 - val_loss: 145.4215\n",
      "Epoch 57/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 144.5697 - val_loss: 145.3474\n",
      "Epoch 58/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 144.4317 - val_loss: 145.3537\n",
      "Epoch 59/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 144.3367 - val_loss: 145.2936\n",
      "Epoch 60/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 144.3170 - val_loss: 145.2326\n",
      "Epoch 61/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 144.2275 - val_loss: 145.2788\n",
      "Epoch 62/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 144.1501 - val_loss: 145.0517\n",
      "Epoch 63/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 144.0439 - val_loss: 145.0948\n",
      "Epoch 64/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 143.9861 - val_loss: 144.9023\n",
      "Epoch 65/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 143.9448 - val_loss: 144.8604\n",
      "Epoch 66/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 143.8598 - val_loss: 144.8693\n",
      "Epoch 67/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 143.8041 - val_loss: 144.8509\n",
      "Epoch 68/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 143.7535 - val_loss: 144.8605\n",
      "Epoch 69/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 143.6857 - val_loss: 144.7085\n",
      "Epoch 70/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 143.6464 - val_loss: 144.6936\n",
      "Epoch 71/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 143.5646 - val_loss: 144.6958\n",
      "Epoch 72/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 143.5226 - val_loss: 144.5573\n",
      "Epoch 73/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 143.4633 - val_loss: 144.6549\n",
      "Epoch 74/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 143.4048 - val_loss: 144.5007\n",
      "Epoch 75/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 143.3624 - val_loss: 144.5152\n",
      "Epoch 76/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 143.2966 - val_loss: 144.4865\n",
      "Epoch 77/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 143.2278 - val_loss: 144.4159\n",
      "Epoch 78/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 143.2455 - val_loss: 144.3313\n",
      "Epoch 79/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 143.1010 - val_loss: 144.3591\n",
      "Epoch 80/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 143.0516 - val_loss: 144.3702\n",
      "Epoch 81/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 143.0451 - val_loss: 144.3030\n",
      "Epoch 82/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 142.9740 - val_loss: 144.1436\n",
      "Epoch 83/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 143.0091 - val_loss: 144.2670\n",
      "Epoch 84/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 142.8848 - val_loss: 144.2930\n",
      "Epoch 85/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 142.9064 - val_loss: 144.2140\n",
      "Epoch 86/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 142.8167 - val_loss: 144.0888\n",
      "Epoch 87/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 142.7808 - val_loss: 144.1077\n",
      "Epoch 88/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 142.7244 - val_loss: 144.1120\n",
      "Epoch 89/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 142.7204 - val_loss: 144.0193\n",
      "Epoch 90/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 142.6470 - val_loss: 144.0223\n",
      "Epoch 91/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 142.6010 - val_loss: 143.9543\n",
      "Epoch 92/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 142.6106 - val_loss: 143.9991\n",
      "Epoch 93/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 142.5629 - val_loss: 143.9141\n",
      "Epoch 94/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 142.5241 - val_loss: 143.9542\n",
      "Epoch 95/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 142.4716 - val_loss: 143.8287\n",
      "Epoch 96/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 142.4655 - val_loss: 143.8559\n",
      "Epoch 97/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 142.3873 - val_loss: 143.8248\n",
      "Epoch 98/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 142.3462 - val_loss: 144.0066\n",
      "Epoch 99/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 142.3288 - val_loss: 143.7552\n",
      "Epoch 100/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 142.2522 - val_loss: 143.8376\n",
      "0.932453674374406\n",
      "1\n",
      "Epoch 1/100\n",
      "209/209 [==============================] - 2s 11ms/step - loss: 273.2515 - val_loss: 201.8120\n",
      "Epoch 2/100\n",
      "209/209 [==============================] - 2s 10ms/step - loss: 193.1024 - val_loss: 187.3382\n",
      "Epoch 3/100\n",
      "209/209 [==============================] - 2s 10ms/step - loss: 185.1133 - val_loss: 181.6351\n",
      "Epoch 4/100\n",
      "209/209 [==============================] - 2s 11ms/step - loss: 180.8507 - val_loss: 178.8791\n",
      "Epoch 5/100\n",
      "209/209 [==============================] - 2s 11ms/step - loss: 177.8670 - val_loss: 176.6975\n",
      "Epoch 6/100\n",
      "209/209 [==============================] - 2s 10ms/step - loss: 175.7575 - val_loss: 175.4425\n",
      "Epoch 7/100\n",
      "209/209 [==============================] - 2s 10ms/step - loss: 174.3166 - val_loss: 174.6049\n",
      "Epoch 8/100\n",
      "209/209 [==============================] - 2s 10ms/step - loss: 173.1274 - val_loss: 173.1816\n",
      "Epoch 9/100\n",
      "209/209 [==============================] - 2s 10ms/step - loss: 172.0399 - val_loss: 172.4011\n",
      "Epoch 10/100\n",
      "209/209 [==============================] - 2s 10ms/step - loss: 171.2140 - val_loss: 171.5974\n",
      "Epoch 11/100\n",
      "209/209 [==============================] - 2s 11ms/step - loss: 170.5061 - val_loss: 170.9616\n",
      "Epoch 12/100\n",
      "209/209 [==============================] - 2s 11ms/step - loss: 169.9626 - val_loss: 170.4531\n",
      "Epoch 13/100\n",
      "209/209 [==============================] - 2s 10ms/step - loss: 169.3679 - val_loss: 170.0292\n",
      "Epoch 14/100\n",
      "209/209 [==============================] - 2s 10ms/step - loss: 168.9158 - val_loss: 169.5308\n",
      "Epoch 15/100\n",
      "209/209 [==============================] - 2s 10ms/step - loss: 168.3035 - val_loss: 168.9418\n",
      "Epoch 16/100\n",
      "209/209 [==============================] - 2s 10ms/step - loss: 167.8057 - val_loss: 168.3009\n",
      "Epoch 17/100\n",
      "209/209 [==============================] - 2s 11ms/step - loss: 167.1989 - val_loss: 167.8221\n",
      "Epoch 18/100\n",
      "209/209 [==============================] - 2s 11ms/step - loss: 166.8458 - val_loss: 167.5222\n",
      "Epoch 19/100\n",
      "209/209 [==============================] - 2s 11ms/step - loss: 166.4279 - val_loss: 167.8734\n",
      "Epoch 20/100\n",
      "209/209 [==============================] - 2s 11ms/step - loss: 166.0599 - val_loss: 166.5032\n",
      "Epoch 21/100\n",
      "209/209 [==============================] - 2s 10ms/step - loss: 165.5787 - val_loss: 166.0592\n",
      "Epoch 22/100\n",
      "209/209 [==============================] - 2s 10ms/step - loss: 165.1268 - val_loss: 165.6983\n",
      "Epoch 23/100\n",
      "209/209 [==============================] - 2s 10ms/step - loss: 164.7820 - val_loss: 165.2872\n",
      "Epoch 24/100\n",
      "209/209 [==============================] - 2s 10ms/step - loss: 164.3970 - val_loss: 165.0361\n",
      "Epoch 25/100\n",
      "209/209 [==============================] - 2s 10ms/step - loss: 164.0533 - val_loss: 164.6877\n",
      "Epoch 26/100\n",
      "209/209 [==============================] - 2s 11ms/step - loss: 163.7348 - val_loss: 164.4291\n",
      "Epoch 27/100\n",
      "209/209 [==============================] - 2s 10ms/step - loss: 163.4300 - val_loss: 164.2597\n",
      "Epoch 28/100\n",
      "209/209 [==============================] - 2s 10ms/step - loss: 163.3306 - val_loss: 163.9822\n",
      "Epoch 29/100\n",
      "209/209 [==============================] - 2s 10ms/step - loss: 163.0472 - val_loss: 163.7592\n",
      "Epoch 30/100\n",
      "209/209 [==============================] - 2s 10ms/step - loss: 162.7211 - val_loss: 163.5853\n",
      "Epoch 31/100\n",
      "209/209 [==============================] - 2s 10ms/step - loss: 162.4589 - val_loss: 163.3817\n",
      "Epoch 32/100\n",
      "209/209 [==============================] - 2s 11ms/step - loss: 162.4912 - val_loss: 163.1665\n",
      "Epoch 33/100\n",
      "209/209 [==============================] - 2s 11ms/step - loss: 162.0676 - val_loss: 162.9072\n",
      "Epoch 34/100\n",
      "209/209 [==============================] - 2s 10ms/step - loss: 161.9053 - val_loss: 162.7580\n",
      "Epoch 35/100\n",
      "209/209 [==============================] - 2s 10ms/step - loss: 161.7770 - val_loss: 163.7283\n",
      "Epoch 36/100\n",
      "209/209 [==============================] - 2s 10ms/step - loss: 161.6378 - val_loss: 162.3790\n",
      "Epoch 37/100\n",
      "209/209 [==============================] - 2s 10ms/step - loss: 161.4258 - val_loss: 162.6071\n",
      "Epoch 38/100\n",
      "209/209 [==============================] - 2s 10ms/step - loss: 161.2681 - val_loss: 162.6971\n",
      "Epoch 39/100\n",
      "209/209 [==============================] - 2s 10ms/step - loss: 161.0549 - val_loss: 162.3560\n",
      "Epoch 40/100\n",
      "209/209 [==============================] - 2s 10ms/step - loss: 160.9767 - val_loss: 162.1057\n",
      "Epoch 41/100\n",
      "209/209 [==============================] - 2s 10ms/step - loss: 160.8386 - val_loss: 162.1682\n",
      "Epoch 42/100\n",
      "209/209 [==============================] - 2s 10ms/step - loss: 160.6441 - val_loss: 161.9220\n",
      "Epoch 43/100\n",
      "209/209 [==============================] - 2s 10ms/step - loss: 160.4879 - val_loss: 161.7286\n",
      "Epoch 44/100\n",
      "209/209 [==============================] - 2s 10ms/step - loss: 160.4303 - val_loss: 162.2110\n",
      "Epoch 45/100\n",
      "209/209 [==============================] - 2s 10ms/step - loss: 160.3923 - val_loss: 161.4539\n",
      "Epoch 46/100\n",
      "209/209 [==============================] - 2s 10ms/step - loss: 160.1932 - val_loss: 161.4498\n",
      "Epoch 47/100\n",
      "209/209 [==============================] - 2s 10ms/step - loss: 160.0335 - val_loss: 161.3441\n",
      "Epoch 48/100\n",
      "209/209 [==============================] - 2s 10ms/step - loss: 160.0196 - val_loss: 161.5076\n",
      "Epoch 49/100\n",
      "209/209 [==============================] - 2s 10ms/step - loss: 159.9126 - val_loss: 161.1373\n",
      "Epoch 50/100\n",
      "209/209 [==============================] - 2s 10ms/step - loss: 159.7292 - val_loss: 161.0288\n",
      "Epoch 51/100\n",
      "209/209 [==============================] - 2s 10ms/step - loss: 159.7052 - val_loss: 161.0923\n",
      "Epoch 52/100\n",
      "209/209 [==============================] - 2s 10ms/step - loss: 159.6683 - val_loss: 160.9521\n",
      "Epoch 53/100\n",
      "209/209 [==============================] - 2s 10ms/step - loss: 159.5898 - val_loss: 161.3136\n",
      "Epoch 54/100\n",
      "209/209 [==============================] - 2s 10ms/step - loss: 159.4745 - val_loss: 161.2855\n",
      "Epoch 55/100\n",
      "209/209 [==============================] - 2s 10ms/step - loss: 159.3387 - val_loss: 160.8496\n",
      "Epoch 56/100\n",
      "209/209 [==============================] - 2s 10ms/step - loss: 159.2034 - val_loss: 160.7735\n",
      "Epoch 57/100\n",
      "209/209 [==============================] - 2s 10ms/step - loss: 159.3047 - val_loss: 160.7097\n",
      "Epoch 58/100\n",
      "209/209 [==============================] - 2s 10ms/step - loss: 159.1071 - val_loss: 160.6901\n",
      "Epoch 59/100\n",
      "209/209 [==============================] - 2s 10ms/step - loss: 159.0400 - val_loss: 160.7587\n",
      "Epoch 60/100\n",
      "209/209 [==============================] - 2s 10ms/step - loss: 158.8783 - val_loss: 160.6081\n",
      "Epoch 61/100\n",
      "209/209 [==============================] - 2s 10ms/step - loss: 158.8509 - val_loss: 160.5621\n",
      "Epoch 62/100\n",
      "209/209 [==============================] - 2s 9ms/step - loss: 158.8887 - val_loss: 160.5122\n",
      "Epoch 63/100\n",
      "209/209 [==============================] - 2s 10ms/step - loss: 158.8499 - val_loss: 160.3434\n",
      "Epoch 64/100\n",
      "209/209 [==============================] - 2s 12ms/step - loss: 158.6780 - val_loss: 161.2979\n",
      "Epoch 65/100\n",
      "209/209 [==============================] - 2s 9ms/step - loss: 158.7245 - val_loss: 160.2625\n",
      "Epoch 66/100\n",
      "209/209 [==============================] - 2s 12ms/step - loss: 158.5713 - val_loss: 160.6412\n",
      "Epoch 67/100\n",
      "209/209 [==============================] - 2s 11ms/step - loss: 158.4917 - val_loss: 160.2973\n",
      "Epoch 68/100\n",
      "209/209 [==============================] - 2s 11ms/step - loss: 158.4591 - val_loss: 160.3240\n",
      "Epoch 69/100\n",
      "209/209 [==============================] - 2s 11ms/step - loss: 158.4308 - val_loss: 160.5225\n",
      "Epoch 70/100\n",
      "209/209 [==============================] - 2s 11ms/step - loss: 158.2446 - val_loss: 160.5198\n",
      "Epoch 71/100\n",
      "209/209 [==============================] - 2s 12ms/step - loss: 158.3751 - val_loss: 159.9760\n",
      "Epoch 72/100\n",
      "209/209 [==============================] - 2s 11ms/step - loss: 158.2567 - val_loss: 160.4530\n",
      "Epoch 73/100\n",
      "209/209 [==============================] - 2s 11ms/step - loss: 158.2575 - val_loss: 161.0423\n",
      "Epoch 74/100\n",
      "209/209 [==============================] - 2s 11ms/step - loss: 158.0826 - val_loss: 159.9100\n",
      "Epoch 75/100\n",
      "209/209 [==============================] - 2s 12ms/step - loss: 158.1072 - val_loss: 160.1311\n",
      "Epoch 76/100\n",
      "209/209 [==============================] - 2s 12ms/step - loss: 158.1137 - val_loss: 159.9749\n",
      "Epoch 77/100\n",
      "209/209 [==============================] - 2s 11ms/step - loss: 157.9912 - val_loss: 159.7342\n",
      "Epoch 78/100\n",
      "209/209 [==============================] - 2s 12ms/step - loss: 157.8941 - val_loss: 160.1718\n",
      "Epoch 79/100\n",
      "209/209 [==============================] - ETA: 0s - loss: 157.864 - 2s 11ms/step - loss: 157.8987 - val_loss: 160.0911\n",
      "Epoch 80/100\n",
      "209/209 [==============================] - 2s 11ms/step - loss: 157.8439 - val_loss: 159.8221\n",
      "Epoch 81/100\n",
      "209/209 [==============================] - 2s 11ms/step - loss: 157.6947 - val_loss: 159.8441\n",
      "Epoch 82/100\n",
      "209/209 [==============================] - 2s 11ms/step - loss: 157.7221 - val_loss: 159.6931\n",
      "Epoch 83/100\n",
      "209/209 [==============================] - 2s 11ms/step - loss: 157.6454 - val_loss: 160.1994\n",
      "Epoch 84/100\n",
      "209/209 [==============================] - 2s 11ms/step - loss: 157.7896 - val_loss: 159.5158\n",
      "Epoch 85/100\n",
      "209/209 [==============================] - 2s 10ms/step - loss: 157.5758 - val_loss: 159.5774\n",
      "Epoch 86/100\n",
      "209/209 [==============================] - 2s 10ms/step - loss: 157.4927 - val_loss: 159.6476\n",
      "Epoch 87/100\n",
      "209/209 [==============================] - 2s 10ms/step - loss: 157.4473 - val_loss: 159.5177\n",
      "Epoch 88/100\n",
      "209/209 [==============================] - 2s 10ms/step - loss: 157.4486 - val_loss: 159.5693\n",
      "Epoch 89/100\n",
      "209/209 [==============================] - 2s 10ms/step - loss: 157.3382 - val_loss: 159.4822\n",
      "Epoch 90/100\n",
      "209/209 [==============================] - 2s 10ms/step - loss: 157.2922 - val_loss: 159.6253\n",
      "Epoch 91/100\n",
      "209/209 [==============================] - 2s 11ms/step - loss: 157.1531 - val_loss: 159.4558\n",
      "Epoch 92/100\n",
      "209/209 [==============================] - 2s 10ms/step - loss: 157.2847 - val_loss: 159.4163\n",
      "Epoch 93/100\n",
      "209/209 [==============================] - 2s 10ms/step - loss: 157.1975 - val_loss: 159.4077\n",
      "Epoch 94/100\n",
      "209/209 [==============================] - 2s 11ms/step - loss: 157.2159 - val_loss: 159.8000\n",
      "Epoch 95/100\n",
      "209/209 [==============================] - 2s 10ms/step - loss: 157.1285 - val_loss: 159.4999\n",
      "Epoch 96/100\n",
      "209/209 [==============================] - 2s 10ms/step - loss: 157.1048 - val_loss: 159.3925\n",
      "Epoch 97/100\n",
      "209/209 [==============================] - 2s 9ms/step - loss: 157.2119 - val_loss: 159.3676\n",
      "Epoch 98/100\n",
      "209/209 [==============================] - 2s 9ms/step - loss: 156.9634 - val_loss: 159.6699\n",
      "Epoch 99/100\n",
      "209/209 [==============================] - 2s 10ms/step - loss: 156.9042 - val_loss: 159.2487\n",
      "Epoch 100/100\n",
      "209/209 [==============================] - 2s 9ms/step - loss: 156.9534 - val_loss: 159.1857\n",
      "0.1589721495461785\n",
      "2\n",
      "Epoch 1/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 252.6577 - val_loss: 191.4819\n",
      "Epoch 2/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 184.4057 - val_loss: 179.5167\n",
      "Epoch 3/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 177.4088 - val_loss: 174.9183\n",
      "Epoch 4/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 173.0675 - val_loss: 170.8686\n",
      "Epoch 5/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 169.0846 - val_loss: 167.9008\n",
      "Epoch 6/100\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 166.4796 - val_loss: 165.8261\n",
      "Epoch 7/100\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 164.3927 - val_loss: 164.0617\n",
      "Epoch 8/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 162.7171 - val_loss: 162.4902\n",
      "Epoch 9/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 161.1695 - val_loss: 161.3331\n",
      "Epoch 10/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 159.8390 - val_loss: 160.0165\n",
      "Epoch 11/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 158.6449 - val_loss: 158.8165\n",
      "Epoch 12/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 157.6074 - val_loss: 157.8232\n",
      "Epoch 13/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 156.5251 - val_loss: 156.9837\n",
      "Epoch 14/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 155.6368 - val_loss: 156.0491\n",
      "Epoch 15/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 154.9512 - val_loss: 155.3250\n",
      "Epoch 16/100\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 154.1909 - val_loss: 154.7764\n",
      "Epoch 17/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 153.5945 - val_loss: 154.1641\n",
      "Epoch 18/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 153.1430 - val_loss: 153.4622\n",
      "Epoch 19/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 152.6301 - val_loss: 153.0670\n",
      "Epoch 20/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 152.1102 - val_loss: 152.7225\n",
      "Epoch 21/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 151.6993 - val_loss: 152.2321\n",
      "Epoch 22/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 151.3133 - val_loss: 151.8798\n",
      "Epoch 23/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 150.9161 - val_loss: 151.5164\n",
      "Epoch 24/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 150.5542 - val_loss: 151.3828\n",
      "Epoch 25/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 150.1667 - val_loss: 150.9633\n",
      "Epoch 26/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 149.8454 - val_loss: 150.6785\n",
      "Epoch 27/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 149.5813 - val_loss: 150.3990\n",
      "Epoch 28/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 149.3164 - val_loss: 150.0682\n",
      "Epoch 29/100\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 148.9652 - val_loss: 150.0505\n",
      "Epoch 30/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 148.7847 - val_loss: 149.6449\n",
      "Epoch 31/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 148.5144 - val_loss: 149.5784\n",
      "Epoch 32/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 148.2150 - val_loss: 149.2516\n",
      "Epoch 33/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 147.9480 - val_loss: 149.1445\n",
      "Epoch 34/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 147.8595 - val_loss: 148.7296\n",
      "Epoch 35/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 147.6434 - val_loss: 148.8025\n",
      "Epoch 36/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 147.4395 - val_loss: 148.7735\n",
      "Epoch 37/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 147.1969 - val_loss: 148.6792\n",
      "Epoch 38/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 146.9039 - val_loss: 148.5605\n",
      "Epoch 39/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 146.7780 - val_loss: 148.2680\n",
      "Epoch 40/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 146.6185 - val_loss: 148.1883\n",
      "Epoch 41/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 146.4742 - val_loss: 147.9560\n",
      "Epoch 42/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 146.3459 - val_loss: 148.0031\n",
      "Epoch 43/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 146.2600 - val_loss: 147.7419\n",
      "Epoch 44/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 146.0015 - val_loss: 147.6953\n",
      "Epoch 45/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 145.9208 - val_loss: 147.5473\n",
      "Epoch 46/100\n",
      "212/212 [==============================] - 3s 14ms/step - loss: 145.8193 - val_loss: 147.4746\n",
      "Epoch 47/100\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 145.6456 - val_loss: 147.3577\n",
      "Epoch 48/100\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 145.5099 - val_loss: 147.2798\n",
      "Epoch 49/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 145.3378 - val_loss: 147.1614\n",
      "Epoch 50/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 145.2094 - val_loss: 147.0997\n",
      "Epoch 51/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 145.1703 - val_loss: 146.9975\n",
      "Epoch 52/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 144.9924 - val_loss: 146.8322\n",
      "Epoch 53/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 144.9597 - val_loss: 146.8422\n",
      "Epoch 54/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 144.9427 - val_loss: 146.6451\n",
      "Epoch 55/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 144.7798 - val_loss: 146.6686\n",
      "Epoch 56/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 144.5576 - val_loss: 146.6388\n",
      "Epoch 57/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 144.5519 - val_loss: 146.4759\n",
      "Epoch 58/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 144.4826 - val_loss: 146.2882\n",
      "Epoch 59/100\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 144.2911 - val_loss: 146.6177\n",
      "Epoch 60/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 144.2317 - val_loss: 146.4610\n",
      "Epoch 61/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 144.1530 - val_loss: 146.1332\n",
      "Epoch 62/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 144.1674 - val_loss: 146.1219\n",
      "Epoch 63/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 143.9647 - val_loss: 145.9849\n",
      "Epoch 64/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 143.8201 - val_loss: 146.1481\n",
      "Epoch 65/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 143.8512 - val_loss: 145.9203\n",
      "Epoch 66/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 143.7332 - val_loss: 145.8429\n",
      "Epoch 67/100\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 143.6237 - val_loss: 146.0818\n",
      "Epoch 68/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 143.5379 - val_loss: 145.6808\n",
      "Epoch 69/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 143.4539 - val_loss: 145.6968\n",
      "Epoch 70/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 143.4142 - val_loss: 145.7251\n",
      "Epoch 71/100\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 143.4522 - val_loss: 145.8044\n",
      "Epoch 72/100\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 143.2911 - val_loss: 145.6578\n",
      "Epoch 73/100\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 143.2386 - val_loss: 145.4232\n",
      "Epoch 74/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 143.1832 - val_loss: 145.5366\n",
      "Epoch 75/100\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 143.1232 - val_loss: 145.4961\n",
      "Epoch 76/100\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 142.9787 - val_loss: 145.4659\n",
      "Epoch 77/100\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 142.9511 - val_loss: 145.5307\n",
      "Epoch 78/100\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 142.9369 - val_loss: 145.2673\n",
      "Epoch 79/100\n",
      "212/212 [==============================] - 2s 7ms/step - loss: 142.8723 - val_loss: 145.1462\n",
      "Epoch 80/100\n",
      "212/212 [==============================] - 2s 7ms/step - loss: 142.7746 - val_loss: 145.2222\n",
      "Epoch 81/100\n",
      "212/212 [==============================] - 2s 7ms/step - loss: 142.7505 - val_loss: 145.3025\n",
      "Epoch 82/100\n",
      "212/212 [==============================] - 2s 7ms/step - loss: 142.7031 - val_loss: 145.2055\n",
      "Epoch 83/100\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 142.6152 - val_loss: 145.0948\n",
      "Epoch 84/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 142.5416 - val_loss: 145.0298\n",
      "Epoch 85/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 142.5245 - val_loss: 144.8948\n",
      "Epoch 86/100\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 142.4515 - val_loss: 145.0411\n",
      "Epoch 87/100\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 142.3666 - val_loss: 144.9144\n",
      "Epoch 88/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 142.3369 - val_loss: 145.1113\n",
      "Epoch 89/100\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 142.3094 - val_loss: 144.9302\n",
      "Epoch 90/100\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 142.2950 - val_loss: 144.7907\n",
      "Epoch 91/100\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 142.2366 - val_loss: 144.7096\n",
      "Epoch 92/100\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 142.1472 - val_loss: 145.1175\n",
      "Epoch 93/100\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 142.1065 - val_loss: 144.7345\n",
      "Epoch 94/100\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 142.0710 - val_loss: 144.5553\n",
      "Epoch 95/100\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 142.0037 - val_loss: 144.5814\n",
      "Epoch 96/100\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 141.9681 - val_loss: 144.6743\n",
      "Epoch 97/100\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 141.9653 - val_loss: 144.5519\n",
      "Epoch 98/100\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 141.9169 - val_loss: 144.8437\n",
      "Epoch 99/100\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 141.8339 - val_loss: 144.6097\n",
      "Epoch 100/100\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 141.8618 - val_loss: 144.6484\n",
      "0.9456212528265876\n",
      "3\n",
      "Epoch 1/100\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 258.4777 - val_loss: 196.9030\n",
      "Epoch 2/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 186.8136 - val_loss: 179.1543\n",
      "Epoch 3/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 175.1896 - val_loss: 170.2095\n",
      "Epoch 4/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 168.6771 - val_loss: 166.2332\n",
      "Epoch 5/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 165.8165 - val_loss: 164.2513\n",
      "Epoch 6/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 164.0341 - val_loss: 162.7535\n",
      "Epoch 7/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 162.5778 - val_loss: 161.5114\n",
      "Epoch 8/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 161.3729 - val_loss: 160.4547\n",
      "Epoch 9/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 160.3482 - val_loss: 159.4114\n",
      "Epoch 10/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 159.4303 - val_loss: 158.6430\n",
      "Epoch 11/100\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 158.6299 - val_loss: 158.0406\n",
      "Epoch 12/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 157.9112 - val_loss: 157.3972\n",
      "Epoch 13/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 157.2824 - val_loss: 156.8842\n",
      "Epoch 14/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 156.7224 - val_loss: 156.4316\n",
      "Epoch 15/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 156.1833 - val_loss: 155.9305\n",
      "Epoch 16/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 155.7099 - val_loss: 155.5316\n",
      "Epoch 17/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 155.2563 - val_loss: 155.1803\n",
      "Epoch 18/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 154.8775 - val_loss: 154.8753\n",
      "Epoch 19/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 154.5265 - val_loss: 154.5819\n",
      "Epoch 20/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 154.1987 - val_loss: 154.2660\n",
      "Epoch 21/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 153.8080 - val_loss: 153.8943\n",
      "Epoch 22/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 153.5009 - val_loss: 153.7694\n",
      "Epoch 23/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 153.2001 - val_loss: 153.4514\n",
      "Epoch 24/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 152.9542 - val_loss: 153.1561\n",
      "Epoch 25/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 152.6858 - val_loss: 153.0644\n",
      "Epoch 26/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 152.3998 - val_loss: 152.6906\n",
      "Epoch 27/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 152.1004 - val_loss: 152.4638\n",
      "Epoch 28/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 151.8240 - val_loss: 152.1224\n",
      "Epoch 29/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 151.5484 - val_loss: 151.9758\n",
      "Epoch 30/100\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 151.2939 - val_loss: 151.7210\n",
      "Epoch 31/100\n",
      "211/211 [==============================] - 2s 10ms/step - loss: 151.0402 - val_loss: 151.4623\n",
      "Epoch 32/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 150.7877 - val_loss: 151.2296\n",
      "Epoch 33/100\n",
      "211/211 [==============================] - 2s 10ms/step - loss: 150.5374 - val_loss: 151.1074\n",
      "Epoch 34/100\n",
      "211/211 [==============================] - 2s 10ms/step - loss: 150.3051 - val_loss: 151.0211\n",
      "Epoch 35/100\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 150.1228 - val_loss: 150.5930\n",
      "Epoch 36/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 149.9260 - val_loss: 150.6424\n",
      "Epoch 37/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 149.7348 - val_loss: 150.2706\n",
      "Epoch 38/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 149.5527 - val_loss: 150.2483\n",
      "Epoch 39/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 149.3433 - val_loss: 150.1680\n",
      "Epoch 40/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 149.1550 - val_loss: 149.8622\n",
      "Epoch 41/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 149.0237 - val_loss: 149.8057\n",
      "Epoch 42/100\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 148.8237 - val_loss: 149.4802\n",
      "Epoch 43/100\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 148.6376 - val_loss: 149.4132\n",
      "Epoch 44/100\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 148.5253 - val_loss: 149.2179\n",
      "Epoch 45/100\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 148.3830 - val_loss: 149.1926\n",
      "Epoch 46/100\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 148.2256 - val_loss: 149.0101\n",
      "Epoch 47/100\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 148.1117 - val_loss: 148.8439\n",
      "Epoch 48/100\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 147.9335 - val_loss: 148.8070\n",
      "Epoch 49/100\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 147.8603 - val_loss: 148.7273\n",
      "Epoch 50/100\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 147.7196 - val_loss: 148.6069\n",
      "Epoch 51/100\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 147.5629 - val_loss: 148.4620\n",
      "Epoch 52/100\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 147.4742 - val_loss: 148.3070\n",
      "Epoch 53/100\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 147.3594 - val_loss: 148.2651\n",
      "Epoch 54/100\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 147.2437 - val_loss: 148.2896\n",
      "Epoch 55/100\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 147.1441 - val_loss: 148.0988\n",
      "Epoch 56/100\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 147.0629 - val_loss: 148.0587\n",
      "Epoch 57/100\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 146.9542 - val_loss: 147.9032\n",
      "Epoch 58/100\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 146.8634 - val_loss: 147.8882\n",
      "Epoch 59/100\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 146.7258 - val_loss: 147.7716\n",
      "Epoch 60/100\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 146.6783 - val_loss: 147.6435\n",
      "Epoch 61/100\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 146.5658 - val_loss: 147.5980\n",
      "Epoch 62/100\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 146.4838 - val_loss: 147.7092\n",
      "Epoch 63/100\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 146.3983 - val_loss: 147.5074\n",
      "Epoch 64/100\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 146.3221 - val_loss: 147.4140\n",
      "Epoch 65/100\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 146.2334 - val_loss: 147.3738\n",
      "Epoch 66/100\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 146.1625 - val_loss: 147.4062\n",
      "Epoch 67/100\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 146.0608 - val_loss: 147.2495\n",
      "Epoch 68/100\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 145.9896 - val_loss: 147.2187\n",
      "Epoch 69/100\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 145.9247 - val_loss: 147.1108\n",
      "Epoch 70/100\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 145.8604 - val_loss: 147.2067\n",
      "Epoch 71/100\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 145.7430 - val_loss: 147.0054\n",
      "Epoch 72/100\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 145.7135 - val_loss: 147.1134\n",
      "Epoch 73/100\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 145.6991 - val_loss: 146.8550\n",
      "Epoch 74/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 145.6153 - val_loss: 147.0928\n",
      "Epoch 75/100\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 145.5577 - val_loss: 146.8922\n",
      "Epoch 76/100\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 145.5109 - val_loss: 146.8928\n",
      "Epoch 77/100\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 145.4062 - val_loss: 146.7435\n",
      "Epoch 78/100\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 145.3822 - val_loss: 146.6917\n",
      "Epoch 79/100\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 145.3062 - val_loss: 146.6698\n",
      "Epoch 80/100\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 145.2612 - val_loss: 146.5247\n",
      "Epoch 81/100\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 145.2210 - val_loss: 146.7921\n",
      "Epoch 82/100\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 145.1508 - val_loss: 146.6948\n",
      "Epoch 83/100\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 145.0668 - val_loss: 146.4290\n",
      "Epoch 84/100\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 145.0185 - val_loss: 146.4606\n",
      "Epoch 85/100\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 145.0149 - val_loss: 146.3345\n",
      "Epoch 86/100\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 144.9162 - val_loss: 146.4455\n",
      "Epoch 87/100\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 144.8781 - val_loss: 146.3684\n",
      "Epoch 88/100\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 144.8090 - val_loss: 146.3116\n",
      "Epoch 89/100\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 144.7849 - val_loss: 146.2775\n",
      "Epoch 90/100\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 144.7412 - val_loss: 146.2899\n",
      "Epoch 91/100\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 144.7134 - val_loss: 146.2324\n",
      "Epoch 92/100\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 144.6672 - val_loss: 146.1982\n",
      "Epoch 93/100\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 144.6231 - val_loss: 146.1801\n",
      "Epoch 94/100\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 144.5781 - val_loss: 146.1953\n",
      "Epoch 95/100\n",
      "211/211 [==============================] - 2s 10ms/step - loss: 144.5477 - val_loss: 146.1071\n",
      "Epoch 96/100\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 144.4590 - val_loss: 146.0583\n",
      "Epoch 97/100\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 144.4645 - val_loss: 146.0975\n",
      "Epoch 98/100\n",
      "211/211 [==============================] - 2s 11ms/step - loss: 144.3857 - val_loss: 145.9968\n",
      "Epoch 99/100\n",
      "211/211 [==============================] - 2s 10ms/step - loss: 144.3342 - val_loss: 146.0794\n",
      "Epoch 100/100\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 144.2977 - val_loss: 146.0246\n",
      "0.819713763367438\n",
      "4\n",
      "Epoch 1/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 256.5606 - val_loss: 195.6694\n",
      "Epoch 2/100\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 189.2175 - val_loss: 184.4605\n",
      "Epoch 3/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 182.3963 - val_loss: 179.0717\n",
      "Epoch 4/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 176.8710 - val_loss: 174.1410\n",
      "Epoch 5/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 172.8746 - val_loss: 171.1126\n",
      "Epoch 6/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 170.3466 - val_loss: 169.1650\n",
      "Epoch 7/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 168.5250 - val_loss: 167.7314\n",
      "Epoch 8/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 167.0748 - val_loss: 166.3210\n",
      "Epoch 9/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 165.7578 - val_loss: 165.0870\n",
      "Epoch 10/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 164.6057 - val_loss: 164.2068\n",
      "Epoch 11/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 163.5213 - val_loss: 163.1940\n",
      "Epoch 12/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 162.6022 - val_loss: 162.4275\n",
      "Epoch 13/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 161.8255 - val_loss: 161.8268\n",
      "Epoch 14/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 161.1253 - val_loss: 161.3753\n",
      "Epoch 15/100\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 160.5347 - val_loss: 160.6678\n",
      "Epoch 16/100\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 159.9585 - val_loss: 160.2179\n",
      "Epoch 17/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 159.4266 - val_loss: 159.7156\n",
      "Epoch 18/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 158.9008 - val_loss: 159.3468\n",
      "Epoch 19/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 158.4269 - val_loss: 158.8520\n",
      "Epoch 20/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 157.9453 - val_loss: 158.4216\n",
      "Epoch 21/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 157.4780 - val_loss: 157.9686\n",
      "Epoch 22/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 157.0637 - val_loss: 157.5493\n",
      "Epoch 23/100\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 156.6488 - val_loss: 157.2511\n",
      "Epoch 24/100\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 156.2718 - val_loss: 156.8064\n",
      "Epoch 25/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 155.8967 - val_loss: 156.4469\n",
      "Epoch 26/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 155.5307 - val_loss: 156.1911\n",
      "Epoch 27/100\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 155.1981 - val_loss: 155.8128\n",
      "Epoch 28/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 154.8644 - val_loss: 155.5195\n",
      "Epoch 29/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 154.5536 - val_loss: 155.3474\n",
      "Epoch 30/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 154.2645 - val_loss: 155.0518\n",
      "Epoch 31/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 154.0300 - val_loss: 154.8383\n",
      "Epoch 32/100\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 153.7268 - val_loss: 154.6064\n",
      "Epoch 33/100\n",
      "212/212 [==============================] - 3s 16ms/step - loss: 153.5501 - val_loss: 154.3043\n",
      "Epoch 34/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 153.2931 - val_loss: 154.3154\n",
      "Epoch 35/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 153.0350 - val_loss: 154.0224\n",
      "Epoch 36/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 152.8636 - val_loss: 153.8701\n",
      "Epoch 37/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 152.6866 - val_loss: 153.8362\n",
      "Epoch 38/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 152.4588 - val_loss: 153.5660\n",
      "Epoch 39/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 152.3097 - val_loss: 153.3984\n",
      "Epoch 40/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 152.1388 - val_loss: 153.3936\n",
      "Epoch 41/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 151.9108 - val_loss: 152.9667\n",
      "Epoch 42/100\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 151.8040 - val_loss: 153.0231\n",
      "Epoch 43/100\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 151.6429 - val_loss: 152.7836\n",
      "Epoch 44/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 151.4580 - val_loss: 152.6809\n",
      "Epoch 45/100\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 151.3281 - val_loss: 152.5631\n",
      "Epoch 46/100\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 151.1942 - val_loss: 152.5055\n",
      "Epoch 47/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 151.0648 - val_loss: 152.3443\n",
      "Epoch 48/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 150.8964 - val_loss: 152.3041\n",
      "Epoch 49/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 150.7753 - val_loss: 152.2556\n",
      "Epoch 50/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 150.6473 - val_loss: 152.0720\n",
      "Epoch 51/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 150.6159 - val_loss: 152.0050\n",
      "Epoch 52/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 150.4046 - val_loss: 151.8582\n",
      "Epoch 53/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 150.2935 - val_loss: 151.9001\n",
      "Epoch 54/100\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 150.1959 - val_loss: 151.6984\n",
      "Epoch 55/100\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 150.0810 - val_loss: 151.6149\n",
      "Epoch 56/100\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 150.0091 - val_loss: 151.4501\n",
      "Epoch 57/100\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 149.8506 - val_loss: 151.3323\n",
      "Epoch 58/100\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 149.8086 - val_loss: 151.4146\n",
      "Epoch 59/100\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 149.7003 - val_loss: 151.3774\n",
      "Epoch 60/100\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 149.6164 - val_loss: 151.3539\n",
      "Epoch 61/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 149.5019 - val_loss: 151.1587\n",
      "Epoch 62/100\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 149.4205 - val_loss: 151.3040\n",
      "Epoch 63/100\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 149.3409 - val_loss: 150.9603\n",
      "Epoch 64/100\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 149.2192 - val_loss: 150.9855\n",
      "Epoch 65/100\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 149.1117 - val_loss: 150.8723\n",
      "Epoch 66/100\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 149.0621 - val_loss: 150.8689\n",
      "Epoch 67/100\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 148.9539 - val_loss: 150.8127\n",
      "Epoch 68/100\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 148.9197 - val_loss: 150.6443\n",
      "Epoch 69/100\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 148.7957 - val_loss: 150.6790\n",
      "Epoch 70/100\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 148.7368 - val_loss: 150.4729\n",
      "Epoch 71/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 148.6666 - val_loss: 150.5074\n",
      "Epoch 72/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 148.6001 - val_loss: 150.5107\n",
      "Epoch 73/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 148.5198 - val_loss: 150.8350\n",
      "Epoch 74/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 148.4476 - val_loss: 150.6416\n",
      "Epoch 75/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 148.3601 - val_loss: 150.5074\n",
      "Epoch 76/100\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 148.3087 - val_loss: 150.3316\n",
      "Epoch 77/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 148.2111 - val_loss: 150.1759\n",
      "Epoch 78/100\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 148.2068 - val_loss: 150.2805\n",
      "Epoch 79/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 148.0705 - val_loss: 150.2340\n",
      "Epoch 80/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 148.0263 - val_loss: 150.1883\n",
      "Epoch 81/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 148.0087 - val_loss: 150.0919\n",
      "Epoch 82/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 147.9327 - val_loss: 150.0988\n",
      "Epoch 83/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 147.8653 - val_loss: 149.9782\n",
      "Epoch 84/100\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 147.8112 - val_loss: 149.9697\n",
      "Epoch 85/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 147.7656 - val_loss: 149.8942\n",
      "Epoch 86/100\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 147.6995 - val_loss: 149.9816\n",
      "Epoch 87/100\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 147.6403 - val_loss: 149.9816\n",
      "Epoch 88/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 147.5764 - val_loss: 149.7433\n",
      "Epoch 89/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 147.5685 - val_loss: 149.8497\n",
      "Epoch 90/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 147.5075 - val_loss: 149.7685\n",
      "Epoch 91/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 147.4052 - val_loss: 149.5797\n",
      "Epoch 92/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 147.3508 - val_loss: 149.5717\n",
      "Epoch 93/100\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 147.3055 - val_loss: 149.5113\n",
      "Epoch 94/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 147.2982 - val_loss: 149.6621\n",
      "Epoch 95/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 147.3039 - val_loss: 149.5407\n",
      "Epoch 96/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 147.1915 - val_loss: 149.3731\n",
      "Epoch 97/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 147.1280 - val_loss: 149.5186\n",
      "Epoch 98/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 147.1084 - val_loss: 149.4163\n",
      "Epoch 99/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 147.0488 - val_loss: 149.4956\n",
      "Epoch 100/100\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 146.9974 - val_loss: 149.3593\n",
      "0.6915651046854017\n",
      "5\n",
      "Epoch 1/100\n",
      "214/214 [==============================] - 2s 11ms/step - loss: 252.2727 - val_loss: 192.3217\n",
      "Epoch 2/100\n",
      "214/214 [==============================] - 2s 10ms/step - loss: 186.4521 - val_loss: 181.2956\n",
      "Epoch 3/100\n",
      "214/214 [==============================] - 2s 10ms/step - loss: 179.4641 - val_loss: 175.6990\n",
      "Epoch 4/100\n",
      "214/214 [==============================] - 2s 10ms/step - loss: 174.0244 - val_loss: 170.3625\n",
      "Epoch 5/100\n",
      "214/214 [==============================] - 2s 10ms/step - loss: 169.6396 - val_loss: 167.1426\n",
      "Epoch 6/100\n",
      "214/214 [==============================] - 2s 11ms/step - loss: 167.1638 - val_loss: 165.3280\n",
      "Epoch 7/100\n",
      "214/214 [==============================] - 2s 11ms/step - loss: 165.5296 - val_loss: 163.9228\n",
      "Epoch 8/100\n",
      "214/214 [==============================] - 2s 10ms/step - loss: 164.2803 - val_loss: 162.7258\n",
      "Epoch 9/100\n",
      "214/214 [==============================] - 2s 11ms/step - loss: 163.2250 - val_loss: 161.8264\n",
      "Epoch 10/100\n",
      "214/214 [==============================] - 2s 10ms/step - loss: 162.3410 - val_loss: 161.0636\n",
      "Epoch 11/100\n",
      "214/214 [==============================] - 2s 9ms/step - loss: 161.5675 - val_loss: 160.4803\n",
      "Epoch 12/100\n",
      "214/214 [==============================] - 2s 9ms/step - loss: 160.8783 - val_loss: 159.7901\n",
      "Epoch 13/100\n",
      "214/214 [==============================] - 2s 10ms/step - loss: 160.2069 - val_loss: 159.1317\n",
      "Epoch 14/100\n",
      "214/214 [==============================] - 2s 10ms/step - loss: 159.5977 - val_loss: 158.6543\n",
      "Epoch 15/100\n",
      "214/214 [==============================] - 2s 10ms/step - loss: 158.9050 - val_loss: 158.1618\n",
      "Epoch 16/100\n",
      "214/214 [==============================] - 2s 10ms/step - loss: 158.3833 - val_loss: 157.5614\n",
      "Epoch 17/100\n",
      "214/214 [==============================] - 2s 10ms/step - loss: 157.8561 - val_loss: 157.2055\n",
      "Epoch 18/100\n",
      "214/214 [==============================] - 2s 10ms/step - loss: 157.3996 - val_loss: 156.9075\n",
      "Epoch 19/100\n",
      "214/214 [==============================] - 2s 10ms/step - loss: 157.0280 - val_loss: 156.3828\n",
      "Epoch 20/100\n",
      "214/214 [==============================] - 2s 10ms/step - loss: 156.6252 - val_loss: 156.2942\n",
      "Epoch 21/100\n",
      "214/214 [==============================] - 2s 11ms/step - loss: 156.3216 - val_loss: 155.8050\n",
      "Epoch 22/100\n",
      "214/214 [==============================] - 2s 10ms/step - loss: 155.9737 - val_loss: 155.5812\n",
      "Epoch 23/100\n",
      "214/214 [==============================] - 2s 10ms/step - loss: 155.6732 - val_loss: 155.3439\n",
      "Epoch 24/100\n",
      "214/214 [==============================] - 2s 10ms/step - loss: 155.3748 - val_loss: 155.0807\n",
      "Epoch 25/100\n",
      "214/214 [==============================] - 2s 10ms/step - loss: 155.1130 - val_loss: 154.8130\n",
      "Epoch 26/100\n",
      "214/214 [==============================] - ETA: 0s - loss: 154.785 - 2s 9ms/step - loss: 154.8229 - val_loss: 154.6823\n",
      "Epoch 27/100\n",
      "214/214 [==============================] - 2s 10ms/step - loss: 154.4759 - val_loss: 154.5074\n",
      "Epoch 28/100\n",
      "214/214 [==============================] - 2s 11ms/step - loss: 154.1906 - val_loss: 154.1118\n",
      "Epoch 29/100\n",
      "214/214 [==============================] - 2s 11ms/step - loss: 153.8854 - val_loss: 153.8625\n",
      "Epoch 30/100\n",
      "214/214 [==============================] - 2s 10ms/step - loss: 153.5896 - val_loss: 153.6791\n",
      "Epoch 31/100\n",
      "214/214 [==============================] - 2s 10ms/step - loss: 153.4058 - val_loss: 153.4452\n",
      "Epoch 32/100\n",
      "214/214 [==============================] - 2s 10ms/step - loss: 153.0653 - val_loss: 153.1815\n",
      "Epoch 33/100\n",
      "214/214 [==============================] - 2s 10ms/step - loss: 152.8401 - val_loss: 152.8339\n",
      "Epoch 34/100\n",
      "214/214 [==============================] - 2s 10ms/step - loss: 152.5583 - val_loss: 152.9245\n",
      "Epoch 35/100\n",
      "214/214 [==============================] - 2s 11ms/step - loss: 152.3168 - val_loss: 152.5852\n",
      "Epoch 36/100\n",
      "214/214 [==============================] - 2s 11ms/step - loss: 152.0583 - val_loss: 152.3923\n",
      "Epoch 37/100\n",
      "214/214 [==============================] - 2s 10ms/step - loss: 151.7840 - val_loss: 152.1543\n",
      "Epoch 38/100\n",
      "214/214 [==============================] - 2s 11ms/step - loss: 151.5321 - val_loss: 152.0025\n",
      "Epoch 39/100\n",
      "214/214 [==============================] - 2s 10ms/step - loss: 151.3393 - val_loss: 151.9055\n",
      "Epoch 40/100\n",
      "214/214 [==============================] - 2s 9ms/step - loss: 151.0936 - val_loss: 151.6497\n",
      "Epoch 41/100\n",
      "214/214 [==============================] - 2s 9ms/step - loss: 150.8667 - val_loss: 151.5234\n",
      "Epoch 42/100\n",
      "214/214 [==============================] - 2s 10ms/step - loss: 150.6818 - val_loss: 151.2919\n",
      "Epoch 43/100\n",
      "214/214 [==============================] - 2s 10ms/step - loss: 150.5070 - val_loss: 151.1723\n",
      "Epoch 44/100\n",
      "214/214 [==============================] - 2s 10ms/step - loss: 150.2384 - val_loss: 151.0805\n",
      "Epoch 45/100\n",
      "214/214 [==============================] - 2s 10ms/step - loss: 150.1014 - val_loss: 150.6947\n",
      "Epoch 46/100\n",
      "214/214 [==============================] - 2s 9ms/step - loss: 149.9503 - val_loss: 150.7390\n",
      "Epoch 47/100\n",
      "214/214 [==============================] - 2s 9ms/step - loss: 149.7848 - val_loss: 150.8385\n",
      "Epoch 48/100\n",
      "214/214 [==============================] - 2s 9ms/step - loss: 149.6747 - val_loss: 150.3860\n",
      "Epoch 49/100\n",
      "214/214 [==============================] - 2s 9ms/step - loss: 149.4564 - val_loss: 150.3560\n",
      "Epoch 50/100\n",
      "214/214 [==============================] - 2s 10ms/step - loss: 149.3614 - val_loss: 150.2971\n",
      "Epoch 51/100\n",
      "214/214 [==============================] - 2s 10ms/step - loss: 149.2503 - val_loss: 150.2360\n",
      "Epoch 52/100\n",
      "214/214 [==============================] - 2s 10ms/step - loss: 149.0939 - val_loss: 149.9569\n",
      "Epoch 53/100\n",
      "214/214 [==============================] - 2s 9ms/step - loss: 148.9784 - val_loss: 149.9339\n",
      "Epoch 54/100\n",
      "214/214 [==============================] - 2s 9ms/step - loss: 148.8240 - val_loss: 149.7849\n",
      "Epoch 55/100\n",
      "214/214 [==============================] - 2s 9ms/step - loss: 148.6968 - val_loss: 149.7893\n",
      "Epoch 56/100\n",
      "214/214 [==============================] - 2s 9ms/step - loss: 148.5933 - val_loss: 149.8104\n",
      "Epoch 57/100\n",
      "214/214 [==============================] - 2s 9ms/step - loss: 148.5260 - val_loss: 149.4871\n",
      "Epoch 58/100\n",
      "214/214 [==============================] - 2s 11ms/step - loss: 148.3405 - val_loss: 149.6637\n",
      "Epoch 59/100\n",
      "214/214 [==============================] - 3s 12ms/step - loss: 148.2487 - val_loss: 149.5525\n",
      "Epoch 60/100\n",
      "214/214 [==============================] - 2s 9ms/step - loss: 148.1894 - val_loss: 149.4703\n",
      "Epoch 61/100\n",
      "214/214 [==============================] - 2s 9ms/step - loss: 148.0556 - val_loss: 149.5213\n",
      "Epoch 62/100\n",
      "214/214 [==============================] - 2s 9ms/step - loss: 148.0289 - val_loss: 149.2699\n",
      "Epoch 63/100\n",
      "214/214 [==============================] - 2s 9ms/step - loss: 147.8385 - val_loss: 149.2363\n",
      "Epoch 64/100\n",
      "214/214 [==============================] - 2s 9ms/step - loss: 147.7498 - val_loss: 149.3297\n",
      "Epoch 65/100\n",
      "214/214 [==============================] - 2s 9ms/step - loss: 147.6118 - val_loss: 149.1365\n",
      "Epoch 66/100\n",
      "214/214 [==============================] - 2s 11ms/step - loss: 147.6103 - val_loss: 148.8013\n",
      "Epoch 67/100\n",
      "214/214 [==============================] - 2s 9ms/step - loss: 147.4453 - val_loss: 148.9045\n",
      "Epoch 68/100\n",
      "214/214 [==============================] - 2s 9ms/step - loss: 147.4104 - val_loss: 148.6760\n",
      "Epoch 69/100\n",
      "214/214 [==============================] - 2s 10ms/step - loss: 147.3262 - val_loss: 148.7548\n",
      "Epoch 70/100\n",
      "214/214 [==============================] - 2s 10ms/step - loss: 147.2312 - val_loss: 148.6556\n",
      "Epoch 71/100\n",
      "214/214 [==============================] - 2s 11ms/step - loss: 147.1459 - val_loss: 148.6402\n",
      "Epoch 72/100\n",
      "214/214 [==============================] - 2s 10ms/step - loss: 147.1201 - val_loss: 148.5357\n",
      "Epoch 73/100\n",
      "214/214 [==============================] - 2s 11ms/step - loss: 146.9996 - val_loss: 148.5740\n",
      "Epoch 74/100\n",
      "214/214 [==============================] - 2s 10ms/step - loss: 146.9509 - val_loss: 148.5076\n",
      "Epoch 75/100\n",
      "214/214 [==============================] - 2s 10ms/step - loss: 146.9029 - val_loss: 148.7274\n",
      "Epoch 76/100\n",
      "214/214 [==============================] - 3s 13ms/step - loss: 146.8241 - val_loss: 148.4613\n",
      "Epoch 77/100\n",
      "214/214 [==============================] - 3s 14ms/step - loss: 146.7089 - val_loss: 148.2871\n",
      "Epoch 78/100\n",
      "214/214 [==============================] - 2s 9ms/step - loss: 146.6073 - val_loss: 148.2971\n",
      "Epoch 79/100\n",
      "214/214 [==============================] - 3s 12ms/step - loss: 146.5305 - val_loss: 148.4562\n",
      "Epoch 80/100\n",
      "214/214 [==============================] - 3s 12ms/step - loss: 146.4576 - val_loss: 148.1792\n",
      "Epoch 81/100\n",
      "214/214 [==============================] - 2s 11ms/step - loss: 146.4427 - val_loss: 148.0937\n",
      "Epoch 82/100\n",
      "214/214 [==============================] - 3s 14ms/step - loss: 146.4600 - val_loss: 148.1697\n",
      "Epoch 83/100\n",
      "214/214 [==============================] - 2s 11ms/step - loss: 146.2719 - val_loss: 148.0982\n",
      "Epoch 84/100\n",
      "214/214 [==============================] - 2s 10ms/step - loss: 146.2552 - val_loss: 147.9376\n",
      "Epoch 85/100\n",
      "214/214 [==============================] - 2s 10ms/step - loss: 146.1321 - val_loss: 147.9553\n",
      "Epoch 86/100\n",
      "214/214 [==============================] - 2s 11ms/step - loss: 146.1470 - val_loss: 148.0507\n",
      "Epoch 87/100\n",
      "214/214 [==============================] - 2s 11ms/step - loss: 146.0632 - val_loss: 147.9745\n",
      "Epoch 88/100\n",
      "214/214 [==============================] - 3s 14ms/step - loss: 146.0049 - val_loss: 147.9725\n",
      "Epoch 89/100\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 145.9597 - val_loss: 147.9124\n",
      "Epoch 90/100\n",
      "214/214 [==============================] - 4s 17ms/step - loss: 145.8734 - val_loss: 148.1283\n",
      "Epoch 91/100\n",
      "214/214 [==============================] - 3s 14ms/step - loss: 145.8190 - val_loss: 147.7357\n",
      "Epoch 92/100\n",
      "214/214 [==============================] - 4s 17ms/step - loss: 145.7217 - val_loss: 147.6308\n",
      "Epoch 93/100\n",
      "214/214 [==============================] - 3s 14ms/step - loss: 145.7261 - val_loss: 147.7754\n",
      "Epoch 94/100\n",
      "214/214 [==============================] - 2s 9ms/step - loss: 145.6978 - val_loss: 147.7025\n",
      "Epoch 95/100\n",
      "214/214 [==============================] - 2s 9ms/step - loss: 145.6626 - val_loss: 147.8124\n",
      "Epoch 96/100\n",
      "214/214 [==============================] - 2s 8ms/step - loss: 145.5275 - val_loss: 147.6274\n",
      "Epoch 97/100\n",
      "214/214 [==============================] - 2s 9ms/step - loss: 145.5310 - val_loss: 147.6615\n",
      "Epoch 98/100\n",
      "214/214 [==============================] - 2s 10ms/step - loss: 145.5602 - val_loss: 147.5140\n",
      "Epoch 99/100\n",
      "214/214 [==============================] - 3s 14ms/step - loss: 145.4314 - val_loss: 147.6505\n",
      "Epoch 100/100\n",
      "214/214 [==============================] - 4s 17ms/step - loss: 145.2822 - val_loss: 147.5353\n",
      "0.8109934153388044\n",
      "6\n",
      "Epoch 1/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 253.3310 - val_loss: 190.6581\n",
      "Epoch 2/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 183.6702 - val_loss: 176.1645\n",
      "Epoch 3/100\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 172.7519 - val_loss: 168.2165\n",
      "Epoch 4/100\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 168.0581 - val_loss: 165.3745\n",
      "Epoch 5/100\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 165.7762 - val_loss: 163.6415\n",
      "Epoch 6/100\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 164.1197 - val_loss: 162.3825\n",
      "Epoch 7/100\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 162.7289 - val_loss: 161.0730\n",
      "Epoch 8/100\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 161.4453 - val_loss: 159.9907\n",
      "Epoch 9/100\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 160.2863 - val_loss: 158.8391\n",
      "Epoch 10/100\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 159.1506 - val_loss: 157.9177\n",
      "Epoch 11/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 158.2277 - val_loss: 157.3112\n",
      "Epoch 12/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 157.5025 - val_loss: 156.5590\n",
      "Epoch 13/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 156.8246 - val_loss: 155.8981\n",
      "Epoch 14/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 156.2043 - val_loss: 155.3002\n",
      "Epoch 15/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 155.7204 - val_loss: 154.8842\n",
      "Epoch 16/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 155.2278 - val_loss: 154.4206\n",
      "Epoch 17/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 154.8124 - val_loss: 154.1013\n",
      "Epoch 18/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 154.4074 - val_loss: 153.7060\n",
      "Epoch 19/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 154.0443 - val_loss: 153.5597\n",
      "Epoch 20/100\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 153.7361 - val_loss: 153.0644\n",
      "Epoch 21/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 153.4069 - val_loss: 153.0349\n",
      "Epoch 22/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 153.1027 - val_loss: 152.6300\n",
      "Epoch 23/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 152.8568 - val_loss: 152.3357\n",
      "Epoch 24/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 152.5858 - val_loss: 152.2037\n",
      "Epoch 25/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 152.2791 - val_loss: 151.9680\n",
      "Epoch 26/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 152.0842 - val_loss: 151.6365\n",
      "Epoch 27/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 151.8468 - val_loss: 151.4283\n",
      "Epoch 28/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 151.6131 - val_loss: 151.1701\n",
      "Epoch 29/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 151.4119 - val_loss: 151.1155\n",
      "Epoch 30/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 151.2337 - val_loss: 151.1442\n",
      "Epoch 31/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 151.0559 - val_loss: 150.6662\n",
      "Epoch 32/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 150.8741 - val_loss: 150.4641\n",
      "Epoch 33/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 150.6204 - val_loss: 150.3645\n",
      "Epoch 34/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 150.4603 - val_loss: 150.2968\n",
      "Epoch 35/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 150.3308 - val_loss: 150.0083\n",
      "Epoch 36/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 150.1110 - val_loss: 149.8351\n",
      "Epoch 37/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 149.9824 - val_loss: 149.7927\n",
      "Epoch 38/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 149.7810 - val_loss: 149.7874\n",
      "Epoch 39/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 149.5916 - val_loss: 149.4160\n",
      "Epoch 40/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 149.4363 - val_loss: 149.5230\n",
      "Epoch 41/100\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 149.3645 - val_loss: 149.2596\n",
      "Epoch 42/100\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 149.1653 - val_loss: 149.1529\n",
      "Epoch 43/100\n",
      "212/212 [==============================] - 2s 8ms/step - loss: 149.0569 - val_loss: 149.0358\n",
      "Epoch 44/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 148.8836 - val_loss: 148.8526\n",
      "Epoch 45/100\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 148.8235 - val_loss: 148.8361\n",
      "Epoch 46/100\n",
      "212/212 [==============================] - 3s 14ms/step - loss: 148.6678 - val_loss: 148.6489\n",
      "Epoch 47/100\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 148.4883 - val_loss: 148.5140\n",
      "Epoch 48/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 148.3923 - val_loss: 148.5934\n",
      "Epoch 49/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 148.3145 - val_loss: 148.2592\n",
      "Epoch 50/100\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 148.1266 - val_loss: 148.1717\n",
      "Epoch 51/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 148.0813 - val_loss: 148.1794\n",
      "Epoch 52/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 147.9667 - val_loss: 148.1946\n",
      "Epoch 53/100\n",
      "212/212 [==============================] - 3s 14ms/step - loss: 147.8525 - val_loss: 148.2821\n",
      "Epoch 54/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 147.7372 - val_loss: 147.8994\n",
      "Epoch 55/100\n",
      "212/212 [==============================] - 3s 14ms/step - loss: 147.6140 - val_loss: 147.9833\n",
      "Epoch 56/100\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 147.5368 - val_loss: 147.9151\n",
      "Epoch 57/100\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 147.4168 - val_loss: 147.8345\n",
      "Epoch 58/100\n",
      "212/212 [==============================] - 3s 16ms/step - loss: 147.3049 - val_loss: 147.6265\n",
      "Epoch 59/100\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 147.2214 - val_loss: 147.5425\n",
      "Epoch 60/100\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 147.1612 - val_loss: 147.4966\n",
      "Epoch 61/100\n",
      "212/212 [==============================] - 3s 14ms/step - loss: 147.0917 - val_loss: 147.4545\n",
      "Epoch 62/100\n",
      "212/212 [==============================] - 3s 14ms/step - loss: 146.9908 - val_loss: 147.3405\n",
      "Epoch 63/100\n",
      "212/212 [==============================] - 3s 16ms/step - loss: 146.8844 - val_loss: 147.3030\n",
      "Epoch 64/100\n",
      "212/212 [==============================] - 4s 18ms/step - loss: 146.8291 - val_loss: 147.2590\n",
      "Epoch 65/100\n",
      "212/212 [==============================] - 3s 16ms/step - loss: 146.7755 - val_loss: 147.2921\n",
      "Epoch 66/100\n",
      "212/212 [==============================] - 4s 20ms/step - loss: 146.6743 - val_loss: 147.1796\n",
      "Epoch 67/100\n",
      "212/212 [==============================] - 5s 25ms/step - loss: 146.6277 - val_loss: 147.1117\n",
      "Epoch 68/100\n",
      "212/212 [==============================] - 5s 25ms/step - loss: 146.4861 - val_loss: 146.9336\n",
      "Epoch 69/100\n",
      "212/212 [==============================] - 5s 24ms/step - loss: 146.3997 - val_loss: 146.9251\n",
      "Epoch 70/100\n",
      "212/212 [==============================] - 5s 25ms/step - loss: 146.3417 - val_loss: 147.0115\n",
      "Epoch 71/100\n",
      "212/212 [==============================] - 6s 28ms/step - loss: 146.3031 - val_loss: 146.7691\n",
      "Epoch 72/100\n",
      "212/212 [==============================] - 6s 27ms/step - loss: 146.2068 - val_loss: 146.8707- ETA: 1s - loss: - ETA: 0s - los\n",
      "Epoch 73/100\n",
      "212/212 [==============================] - 5s 24ms/step - loss: 146.1438 - val_loss: 146.6977\n",
      "Epoch 74/100\n",
      "212/212 [==============================] - 6s 29ms/step - loss: 146.0593 - val_loss: 146.7931\n",
      "Epoch 75/100\n",
      "212/212 [==============================] - 6s 27ms/step - loss: 146.0235 - val_loss: 146.6349\n",
      "Epoch 76/100\n",
      "212/212 [==============================] - 5s 24ms/step - loss: 145.9691 - val_loss: 146.6572\n",
      "Epoch 77/100\n",
      "212/212 [==============================] - 5s 26ms/step - loss: 145.8823 - val_loss: 146.6639 - loss: 145\n",
      "Epoch 78/100\n",
      "212/212 [==============================] - 5s 25ms/step - loss: 145.8069 - val_loss: 146.5101\n",
      "Epoch 79/100\n",
      "212/212 [==============================] - 5s 22ms/step - loss: 145.6912 - val_loss: 146.4244\n",
      "Epoch 80/100\n",
      "212/212 [==============================] - 5s 22ms/step - loss: 145.6632 - val_loss: 146.4638\n",
      "Epoch 81/100\n",
      "212/212 [==============================] - 5s 24ms/step - loss: 145.6071 - val_loss: 146.4022\n",
      "Epoch 82/100\n",
      "212/212 [==============================] - 6s 26ms/step - loss: 145.5113 - val_loss: 146.3050\n",
      "Epoch 83/100\n",
      "212/212 [==============================] - 5s 24ms/step - loss: 145.4323 - val_loss: 146.2917\n",
      "Epoch 84/100\n",
      "212/212 [==============================] - 5s 23ms/step - loss: 145.3926 - val_loss: 146.2438s - los - ETA\n",
      "Epoch 85/100\n",
      "212/212 [==============================] - 5s 21ms/step - loss: 145.3706 - val_loss: 146.2864\n",
      "Epoch 86/100\n",
      "212/212 [==============================] - 5s 22ms/step - loss: 145.3089 - val_loss: 146.1107\n",
      "Epoch 87/100\n",
      "212/212 [==============================] - 5s 22ms/step - loss: 145.2059 - val_loss: 146.0715\n",
      "Epoch 88/100\n",
      "212/212 [==============================] - 4s 21ms/step - loss: 145.1504 - val_loss: 146.1066\n",
      "Epoch 89/100\n",
      "212/212 [==============================] - 4s 21ms/step - loss: 145.1208 - val_loss: 146.0118\n",
      "Epoch 90/100\n",
      "212/212 [==============================] - 4s 21ms/step - loss: 145.0366 - val_loss: 146.0191\n",
      "Epoch 91/100\n",
      "212/212 [==============================] - 4s 19ms/step - loss: 144.9813 - val_loss: 146.0407\n",
      "Epoch 92/100\n",
      "212/212 [==============================] - 4s 19ms/step - loss: 144.8942 - val_loss: 145.9612\n",
      "Epoch 93/100\n",
      "212/212 [==============================] - 4s 19ms/step - loss: 144.8941 - val_loss: 145.9144\n",
      "Epoch 94/100\n",
      "212/212 [==============================] - 4s 19ms/step - loss: 144.8095 - val_loss: 145.8165\n",
      "Epoch 95/100\n",
      "212/212 [==============================] - 4s 19ms/step - loss: 144.7709 - val_loss: 145.8588\n",
      "Epoch 96/100\n",
      "212/212 [==============================] - 4s 17ms/step - loss: 144.7895 - val_loss: 145.6739\n",
      "Epoch 97/100\n",
      "212/212 [==============================] - 4s 19ms/step - loss: 144.7043 - val_loss: 145.7350\n",
      "Epoch 98/100\n",
      "212/212 [==============================] - 4s 19ms/step - loss: 144.6327 - val_loss: 145.7402\n",
      "Epoch 99/100\n",
      "212/212 [==============================] - 4s 18ms/step - loss: 144.5734 - val_loss: 145.8577\n",
      "Epoch 100/100\n",
      "212/212 [==============================] - 4s 17ms/step - loss: 144.5226 - val_loss: 145.7679\n",
      "0.9282194574241568\n",
      "7\n",
      "Epoch 1/100\n",
      "210/210 [==============================] - 4s 20ms/step - loss: 261.0350 - val_loss: 194.6708\n",
      "Epoch 2/100\n",
      "210/210 [==============================] - 3s 16ms/step - loss: 187.3407 - val_loss: 183.3435\n",
      "Epoch 3/100\n",
      "210/210 [==============================] - 3s 17ms/step - loss: 180.7446 - val_loss: 178.3404\n",
      "Epoch 4/100\n",
      "210/210 [==============================] - 4s 17ms/step - loss: 176.1601 - val_loss: 173.8354\n",
      "Epoch 5/100\n",
      "210/210 [==============================] - 4s 17ms/step - loss: 171.8936 - val_loss: 169.8418\n",
      "Epoch 6/100\n",
      "210/210 [==============================] - 4s 18ms/step - loss: 168.8367 - val_loss: 167.6402\n",
      "Epoch 7/100\n",
      "210/210 [==============================] - 3s 16ms/step - loss: 167.2232 - val_loss: 166.4101\n",
      "Epoch 8/100\n",
      "210/210 [==============================] - 3s 16ms/step - loss: 166.1369 - val_loss: 165.4078\n",
      "Epoch 9/100\n",
      "210/210 [==============================] - 3s 16ms/step - loss: 165.2914 - val_loss: 164.6782\n",
      "Epoch 10/100\n",
      "210/210 [==============================] - 4s 17ms/step - loss: 164.5273 - val_loss: 163.9018\n",
      "Epoch 11/100\n",
      "210/210 [==============================] - 3s 16ms/step - loss: 163.7808 - val_loss: 163.3683\n",
      "Epoch 12/100\n",
      "210/210 [==============================] - 3s 16ms/step - loss: 163.0695 - val_loss: 162.7754\n",
      "Epoch 13/100\n",
      "210/210 [==============================] - 4s 17ms/step - loss: 162.4863 - val_loss: 162.1951\n",
      "Epoch 14/100\n",
      "210/210 [==============================] - 4s 17ms/step - loss: 161.8792 - val_loss: 161.8070\n",
      "Epoch 15/100\n",
      "210/210 [==============================] - 4s 18ms/step - loss: 161.3955 - val_loss: 161.2222\n",
      "Epoch 16/100\n",
      "210/210 [==============================] - 3s 16ms/step - loss: 160.9013 - val_loss: 160.9515\n",
      "Epoch 17/100\n",
      "210/210 [==============================] - 3s 16ms/step - loss: 160.4634 - val_loss: 160.4567\n",
      "Epoch 18/100\n",
      "210/210 [==============================] - 4s 17ms/step - loss: 160.0083 - val_loss: 160.0076\n",
      "Epoch 19/100\n",
      "210/210 [==============================] - 3s 16ms/step - loss: 159.5968 - val_loss: 159.8201\n",
      "Epoch 20/100\n",
      "210/210 [==============================] - 3s 16ms/step - loss: 159.1939 - val_loss: 159.3430\n",
      "Epoch 21/100\n",
      "210/210 [==============================] - 3s 16ms/step - loss: 158.8331 - val_loss: 159.0906\n",
      "Epoch 22/100\n",
      "210/210 [==============================] - 3s 15ms/step - loss: 158.5077 - val_loss: 158.8785\n",
      "Epoch 23/100\n",
      "210/210 [==============================] - 3s 16ms/step - loss: 158.1615 - val_loss: 158.5936\n",
      "Epoch 24/100\n",
      "210/210 [==============================] - 3s 16ms/step - loss: 157.8652 - val_loss: 158.3823\n",
      "Epoch 25/100\n",
      "210/210 [==============================] - 3s 16ms/step - loss: 157.5905 - val_loss: 158.0230\n",
      "Epoch 26/100\n",
      "210/210 [==============================] - 3s 15ms/step - loss: 157.2906 - val_loss: 157.9224\n",
      "Epoch 27/100\n",
      "210/210 [==============================] - 3s 14ms/step - loss: 157.0739 - val_loss: 157.6664\n",
      "Epoch 28/100\n",
      "210/210 [==============================] - 3s 14ms/step - loss: 156.8618 - val_loss: 157.5161\n",
      "Epoch 29/100\n",
      "210/210 [==============================] - 3s 15ms/step - loss: 156.6166 - val_loss: 157.3113\n",
      "Epoch 30/100\n",
      "210/210 [==============================] - 3s 15ms/step - loss: 156.3828 - val_loss: 157.0574\n",
      "Epoch 31/100\n",
      "210/210 [==============================] - 3s 14ms/step - loss: 156.1952 - val_loss: 156.9267\n",
      "Epoch 32/100\n",
      "210/210 [==============================] - 3s 14ms/step - loss: 155.9583 - val_loss: 156.7768\n",
      "Epoch 33/100\n",
      "210/210 [==============================] - 3s 14ms/step - loss: 155.7454 - val_loss: 156.5044\n",
      "Epoch 34/100\n",
      "210/210 [==============================] - 3s 15ms/step - loss: 155.5625 - val_loss: 156.5301\n",
      "Epoch 35/100\n",
      "210/210 [==============================] - 3s 14ms/step - loss: 155.3630 - val_loss: 156.2414\n",
      "Epoch 36/100\n",
      "210/210 [==============================] - 3s 14ms/step - loss: 155.1963 - val_loss: 156.1252\n",
      "Epoch 37/100\n",
      "210/210 [==============================] - 3s 14ms/step - loss: 154.9541 - val_loss: 155.9907\n",
      "Epoch 38/100\n",
      "210/210 [==============================] - 3s 14ms/step - loss: 154.8254 - val_loss: 155.7192\n",
      "Epoch 39/100\n",
      "210/210 [==============================] - 3s 15ms/step - loss: 154.6066 - val_loss: 155.7015\n",
      "Epoch 40/100\n",
      "210/210 [==============================] - 3s 14ms/step - loss: 154.4138 - val_loss: 155.3342\n",
      "Epoch 41/100\n",
      "210/210 [==============================] - 3s 14ms/step - loss: 154.2744 - val_loss: 155.2291\n",
      "Epoch 42/100\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 154.0793 - val_loss: 155.0436\n",
      "Epoch 43/100\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 153.9766 - val_loss: 155.2192\n",
      "Epoch 44/100\n",
      "210/210 [==============================] - 3s 14ms/step - loss: 153.7926 - val_loss: 154.9520\n",
      "Epoch 45/100\n",
      "210/210 [==============================] - 3s 14ms/step - loss: 153.6589 - val_loss: 154.7180\n",
      "Epoch 46/100\n",
      "210/210 [==============================] - 3s 14ms/step - loss: 153.4953 - val_loss: 154.5964\n",
      "Epoch 47/100\n",
      "210/210 [==============================] - 3s 14ms/step - loss: 153.3619 - val_loss: 154.5527\n",
      "Epoch 48/100\n",
      "210/210 [==============================] - 3s 16ms/step - loss: 153.2239 - val_loss: 154.4186\n",
      "Epoch 49/100\n",
      "210/210 [==============================] - 3s 14ms/step - loss: 153.0994 - val_loss: 154.3118\n",
      "Epoch 50/100\n",
      "210/210 [==============================] - 3s 14ms/step - loss: 152.9444 - val_loss: 154.2444\n",
      "Epoch 51/100\n",
      "210/210 [==============================] - 3s 14ms/step - loss: 152.8191 - val_loss: 154.0657\n",
      "Epoch 52/100\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 152.7124 - val_loss: 153.8501\n",
      "Epoch 53/100\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 152.5822 - val_loss: 153.9045\n",
      "Epoch 54/100\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 152.4621 - val_loss: 153.7715\n",
      "Epoch 55/100\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 152.3440 - val_loss: 153.5902\n",
      "Epoch 56/100\n",
      "210/210 [==============================] - 3s 14ms/step - loss: 152.2259 - val_loss: 153.5063\n",
      "Epoch 57/100\n",
      "210/210 [==============================] - 3s 14ms/step - loss: 152.1201 - val_loss: 153.4835\n",
      "Epoch 58/100\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 152.0529 - val_loss: 153.4951\n",
      "Epoch 59/100\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 151.9301 - val_loss: 153.2263\n",
      "Epoch 60/100\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 151.7967 - val_loss: 153.1928\n",
      "Epoch 61/100\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 151.6993 - val_loss: 153.1816\n",
      "Epoch 62/100\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 151.6502 - val_loss: 153.0868\n",
      "Epoch 63/100\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 151.5403 - val_loss: 152.9919\n",
      "Epoch 64/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 151.4426 - val_loss: 152.9344\n",
      "Epoch 65/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 151.3484 - val_loss: 152.8778\n",
      "Epoch 66/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 151.2521 - val_loss: 152.8347\n",
      "Epoch 67/100\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 151.1986 - val_loss: 152.7125\n",
      "Epoch 68/100\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 151.1230 - val_loss: 152.7696\n",
      "Epoch 69/100\n",
      "210/210 [==============================] - 3s 14ms/step - loss: 151.0138 - val_loss: 152.6298\n",
      "Epoch 70/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 150.9737 - val_loss: 152.6115\n",
      "Epoch 71/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 150.8891 - val_loss: 152.4433\n",
      "Epoch 72/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 150.8014 - val_loss: 152.3748\n",
      "Epoch 73/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 150.7897 - val_loss: 152.4764\n",
      "Epoch 74/100\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 150.6783 - val_loss: 152.4823\n",
      "Epoch 75/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 150.6470 - val_loss: 152.3736\n",
      "Epoch 76/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 150.5204 - val_loss: 152.4725\n",
      "Epoch 77/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 150.4577 - val_loss: 152.3905\n",
      "Epoch 78/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 150.4022 - val_loss: 152.3720\n",
      "Epoch 79/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 150.3258 - val_loss: 152.2294\n",
      "Epoch 80/100\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 150.2308 - val_loss: 152.1475\n",
      "Epoch 81/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 150.2459 - val_loss: 152.1212\n",
      "Epoch 82/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 150.1377 - val_loss: 152.0287\n",
      "Epoch 83/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 150.0463 - val_loss: 152.0858: 0s - loss: 15\n",
      "Epoch 84/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 150.0179 - val_loss: 151.9097\n",
      "Epoch 85/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 149.9752 - val_loss: 151.9809\n",
      "Epoch 86/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 149.9128 - val_loss: 151.9003\n",
      "Epoch 87/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 149.8702 - val_loss: 151.8505\n",
      "Epoch 88/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 149.8419 - val_loss: 151.9523\n",
      "Epoch 89/100\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 149.7510 - val_loss: 151.7962\n",
      "Epoch 90/100\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 149.7554 - val_loss: 151.7239\n",
      "Epoch 91/100\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 149.6940 - val_loss: 151.6081\n",
      "Epoch 92/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 149.6158 - val_loss: 151.6493\n",
      "Epoch 93/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 149.5461 - val_loss: 151.6915\n",
      "Epoch 94/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 149.5269 - val_loss: 151.5180\n",
      "Epoch 95/100\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 149.4421 - val_loss: 151.5939\n",
      "Epoch 96/100\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 149.4401 - val_loss: 151.5411\n",
      "Epoch 97/100\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 149.4179 - val_loss: 151.5587\n",
      "Epoch 98/100\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 149.3402 - val_loss: 151.4363\n",
      "Epoch 99/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 149.2586 - val_loss: 151.4518\n",
      "Epoch 100/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 149.2101 - val_loss: 151.4039\n",
      "0.5866674921198853\n",
      "8\n",
      "Epoch 1/100\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 260.7307 - val_loss: 198.2488\n",
      "Epoch 2/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 188.3730 - val_loss: 181.0399\n",
      "Epoch 3/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 177.1979 - val_loss: 171.5711\n",
      "Epoch 4/100\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 169.5084 - val_loss: 166.3289\n",
      "Epoch 5/100\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 166.3360 - val_loss: 164.3562\n",
      "Epoch 6/100\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 164.8364 - val_loss: 163.1650\n",
      "Epoch 7/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 163.7993 - val_loss: 162.2898\n",
      "Epoch 8/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 162.9378 - val_loss: 161.5402\n",
      "Epoch 9/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 162.1683 - val_loss: 160.8555\n",
      "Epoch 10/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 161.4263 - val_loss: 160.2540\n",
      "Epoch 11/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 160.7249 - val_loss: 159.7224\n",
      "Epoch 12/100\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 160.0496 - val_loss: 159.2414\n",
      "Epoch 13/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 159.4304 - val_loss: 158.6501\n",
      "Epoch 14/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 158.7713 - val_loss: 158.1714\n",
      "Epoch 15/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 158.1497 - val_loss: 157.8035\n",
      "Epoch 16/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 157.5381 - val_loss: 157.2040\n",
      "Epoch 17/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 156.9458 - val_loss: 156.6698\n",
      "Epoch 18/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 156.3818 - val_loss: 156.2990\n",
      "Epoch 19/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 155.8902 - val_loss: 156.0145\n",
      "Epoch 20/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 155.4435 - val_loss: 155.6396\n",
      "Epoch 21/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 155.0287 - val_loss: 155.1268\n",
      "Epoch 22/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 154.6377 - val_loss: 154.8543\n",
      "Epoch 23/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 154.3068 - val_loss: 154.5915\n",
      "Epoch 24/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 153.9662 - val_loss: 154.3365\n",
      "Epoch 25/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 153.6692 - val_loss: 154.0870\n",
      "Epoch 26/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 153.4065 - val_loss: 153.8812\n",
      "Epoch 27/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 153.1358 - val_loss: 153.5956\n",
      "Epoch 28/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 152.8987 - val_loss: 153.4851\n",
      "Epoch 29/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 152.6291 - val_loss: 153.2233\n",
      "Epoch 30/100\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 152.4258 - val_loss: 153.0340\n",
      "Epoch 31/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 152.1992 - val_loss: 152.8666\n",
      "Epoch 32/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 151.9742 - val_loss: 152.7687\n",
      "Epoch 33/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 151.8393 - val_loss: 152.4721\n",
      "Epoch 34/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 151.6159 - val_loss: 152.3298\n",
      "Epoch 35/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 151.3913 - val_loss: 152.2257\n",
      "Epoch 36/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 151.2233 - val_loss: 152.0347\n",
      "Epoch 37/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 151.0676 - val_loss: 151.8604\n",
      "Epoch 38/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 150.8763 - val_loss: 151.6554\n",
      "Epoch 39/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 150.7335 - val_loss: 151.6559\n",
      "Epoch 40/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 150.5632 - val_loss: 151.3371\n",
      "Epoch 41/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 150.3835 - val_loss: 151.2312\n",
      "Epoch 42/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 150.2605 - val_loss: 151.2671\n",
      "Epoch 43/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 150.0665 - val_loss: 151.1349\n",
      "Epoch 44/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 149.8907 - val_loss: 150.9017\n",
      "Epoch 45/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 149.7689 - val_loss: 150.8101\n",
      "Epoch 46/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 149.6420 - val_loss: 150.7177\n",
      "Epoch 47/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 149.4971 - val_loss: 150.5778\n",
      "Epoch 48/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 149.3553 - val_loss: 150.5461\n",
      "Epoch 49/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 149.1938 - val_loss: 150.4212\n",
      "Epoch 50/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 149.0954 - val_loss: 150.2580\n",
      "Epoch 51/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 148.9450 - val_loss: 150.1698\n",
      "Epoch 52/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 148.8534 - val_loss: 150.1866\n",
      "Epoch 53/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 148.6964 - val_loss: 149.9876\n",
      "Epoch 54/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 148.5729 - val_loss: 149.9236\n",
      "Epoch 55/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 148.4514 - val_loss: 149.7518\n",
      "Epoch 56/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 148.3368 - val_loss: 149.7196\n",
      "Epoch 57/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 148.2315 - val_loss: 149.5862\n",
      "Epoch 58/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 148.1329 - val_loss: 149.4575\n",
      "Epoch 59/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 147.9828 - val_loss: 149.4809\n",
      "Epoch 60/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 147.8869 - val_loss: 149.2185\n",
      "Epoch 61/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 147.7860 - val_loss: 149.2288\n",
      "Epoch 62/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 147.6447 - val_loss: 149.0966\n",
      "Epoch 63/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 147.5642 - val_loss: 149.1249\n",
      "Epoch 64/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 147.4679 - val_loss: 148.9393\n",
      "Epoch 65/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 147.3592 - val_loss: 148.8938\n",
      "Epoch 66/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 147.2463 - val_loss: 148.8599\n",
      "Epoch 67/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 147.1268 - val_loss: 148.7044\n",
      "Epoch 68/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 147.0591 - val_loss: 148.6161\n",
      "Epoch 69/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 146.9760 - val_loss: 148.5904\n",
      "Epoch 70/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 146.8683 - val_loss: 148.4710\n",
      "Epoch 71/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 146.7818 - val_loss: 148.4859\n",
      "Epoch 72/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 146.7123 - val_loss: 148.4384\n",
      "Epoch 73/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 146.6353 - val_loss: 148.3483\n",
      "Epoch 74/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 146.5251 - val_loss: 148.2470\n",
      "Epoch 75/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 146.4836 - val_loss: 148.4182\n",
      "Epoch 76/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 146.3899 - val_loss: 148.1662\n",
      "Epoch 77/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 146.2915 - val_loss: 148.0154\n",
      "Epoch 78/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 146.2389 - val_loss: 147.9832\n",
      "Epoch 79/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 146.1319 - val_loss: 148.0227\n",
      "Epoch 80/100\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 146.1009 - val_loss: 148.0310\n",
      "Epoch 81/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 146.0178 - val_loss: 147.8457\n",
      "Epoch 82/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 145.9191 - val_loss: 147.7513\n",
      "Epoch 83/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 145.8527 - val_loss: 147.7375\n",
      "Epoch 84/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 145.8082 - val_loss: 147.7081\n",
      "Epoch 85/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 145.7315 - val_loss: 147.6570\n",
      "Epoch 86/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 145.6687 - val_loss: 147.6450\n",
      "Epoch 87/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 145.6455 - val_loss: 147.6015\n",
      "Epoch 88/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 145.5583 - val_loss: 147.7103\n",
      "Epoch 89/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 145.4762 - val_loss: 147.5720\n",
      "Epoch 90/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 145.4132 - val_loss: 147.5052\n",
      "Epoch 91/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 145.3889 - val_loss: 147.3586\n",
      "Epoch 92/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 145.3253 - val_loss: 147.3928\n",
      "Epoch 93/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 145.2763 - val_loss: 147.2921\n",
      "Epoch 94/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 145.1676 - val_loss: 147.3942\n",
      "Epoch 95/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 145.1615 - val_loss: 147.2927\n",
      "Epoch 96/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 145.1007 - val_loss: 147.2005\n",
      "Epoch 97/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 145.0413 - val_loss: 147.3029\n",
      "Epoch 98/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 145.0042 - val_loss: 147.1237\n",
      "Epoch 99/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 144.9552 - val_loss: 147.1346\n",
      "Epoch 100/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 144.9000 - val_loss: 147.3183\n",
      "0.7646198115323699\n",
      "9\n",
      "Epoch 1/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 259.7159 - val_loss: 196.2903\n",
      "Epoch 2/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 189.7789 - val_loss: 183.7677\n",
      "Epoch 3/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 179.8579 - val_loss: 175.6823\n",
      "Epoch 4/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 174.1417 - val_loss: 171.5914\n",
      "Epoch 5/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 171.0447 - val_loss: 169.0933\n",
      "Epoch 6/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 168.9775 - val_loss: 167.2863\n",
      "Epoch 7/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 167.1231 - val_loss: 165.8988\n",
      "Epoch 8/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 165.5638 - val_loss: 164.5821\n",
      "Epoch 9/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 164.2789 - val_loss: 163.5653\n",
      "Epoch 10/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 163.2915 - val_loss: 162.7198\n",
      "Epoch 11/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 162.4057 - val_loss: 162.0687\n",
      "Epoch 12/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 161.6784 - val_loss: 161.5262\n",
      "Epoch 13/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 161.1126 - val_loss: 160.8751\n",
      "Epoch 14/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 160.5324 - val_loss: 160.8344\n",
      "Epoch 15/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 160.0005 - val_loss: 160.1360\n",
      "Epoch 16/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 159.5543 - val_loss: 159.8533\n",
      "Epoch 17/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 159.1613 - val_loss: 159.3230\n",
      "Epoch 18/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 158.7908 - val_loss: 159.0143\n",
      "Epoch 19/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 158.4109 - val_loss: 158.8665\n",
      "Epoch 20/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 158.1616 - val_loss: 158.4386\n",
      "Epoch 21/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 157.7273 - val_loss: 158.2000\n",
      "Epoch 22/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 157.4419 - val_loss: 157.7760\n",
      "Epoch 23/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 157.1848 - val_loss: 157.7643\n",
      "Epoch 24/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 156.8339 - val_loss: 157.2923\n",
      "Epoch 25/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 156.5401 - val_loss: 156.9520\n",
      "Epoch 26/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 156.2507 - val_loss: 156.8020\n",
      "Epoch 27/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 156.0205 - val_loss: 156.5557\n",
      "Epoch 28/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 155.7611 - val_loss: 156.5475\n",
      "Epoch 29/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 155.4802 - val_loss: 156.2267\n",
      "Epoch 30/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 155.3227 - val_loss: 155.9599\n",
      "Epoch 31/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 155.0481 - val_loss: 155.6639\n",
      "Epoch 32/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 154.7901 - val_loss: 155.5321\n",
      "Epoch 33/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 154.5907 - val_loss: 155.2713\n",
      "Epoch 34/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 154.3971 - val_loss: 155.1418\n",
      "Epoch 35/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 154.2491 - val_loss: 154.9095\n",
      "Epoch 36/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 154.0073 - val_loss: 155.0198\n",
      "Epoch 37/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 153.8623 - val_loss: 154.8618\n",
      "Epoch 38/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 153.7771 - val_loss: 154.6085\n",
      "Epoch 39/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 153.5577 - val_loss: 154.4488\n",
      "Epoch 40/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 153.4088 - val_loss: 154.3121\n",
      "Epoch 41/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 153.2494 - val_loss: 154.2465\n",
      "Epoch 42/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 153.0863 - val_loss: 154.0462\n",
      "Epoch 43/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 152.9710 - val_loss: 154.0688\n",
      "Epoch 44/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 152.8225 - val_loss: 153.7759\n",
      "Epoch 45/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 152.6915 - val_loss: 153.9642\n",
      "Epoch 46/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 152.5882 - val_loss: 153.6846\n",
      "Epoch 47/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 152.4457 - val_loss: 153.4564\n",
      "Epoch 48/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 152.3524 - val_loss: 153.5225\n",
      "Epoch 49/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 152.2238 - val_loss: 153.5054\n",
      "Epoch 50/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 152.0883 - val_loss: 153.3745\n",
      "Epoch 51/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 151.9444 - val_loss: 153.3093\n",
      "Epoch 52/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 152.0109 - val_loss: 153.2781\n",
      "Epoch 53/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 151.8119 - val_loss: 152.9780\n",
      "Epoch 54/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 151.6866 - val_loss: 152.9391\n",
      "Epoch 55/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 151.6324 - val_loss: 152.8506\n",
      "Epoch 56/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 151.4583 - val_loss: 152.7258\n",
      "Epoch 57/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 151.4171 - val_loss: 152.7778\n",
      "Epoch 58/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 151.2924 - val_loss: 152.5933\n",
      "Epoch 59/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 151.1759 - val_loss: 152.5600\n",
      "Epoch 60/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 151.1603 - val_loss: 152.5156\n",
      "Epoch 61/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 151.0184 - val_loss: 152.3955\n",
      "Epoch 62/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 150.8245 - val_loss: 152.2622\n",
      "Epoch 63/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 150.7205 - val_loss: 152.2331\n",
      "Epoch 64/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 150.7625 - val_loss: 152.1262\n",
      "Epoch 65/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 150.6182 - val_loss: 152.0342\n",
      "Epoch 66/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 150.5596 - val_loss: 151.9451\n",
      "Epoch 67/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 150.5238 - val_loss: 151.9240\n",
      "Epoch 68/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 150.3447 - val_loss: 151.8716\n",
      "Epoch 69/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 150.2652 - val_loss: 151.8545\n",
      "Epoch 70/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 150.2108 - val_loss: 151.7763\n",
      "Epoch 71/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 150.0869 - val_loss: 151.5602\n",
      "Epoch 72/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 150.0683 - val_loss: 151.6007\n",
      "Epoch 73/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 150.0095 - val_loss: 151.5716\n",
      "Epoch 74/100\n",
      "212/212 [==============================] - 2s 10ms/step - loss: 149.9052 - val_loss: 151.5154\n",
      "Epoch 75/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 149.7841 - val_loss: 151.4136\n",
      "Epoch 76/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 149.8108 - val_loss: 151.2886\n",
      "Epoch 77/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 149.6797 - val_loss: 151.1568\n",
      "Epoch 78/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 149.6295 - val_loss: 151.2721\n",
      "Epoch 79/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 149.5993 - val_loss: 151.1688\n",
      "Epoch 80/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 149.4789 - val_loss: 151.1357\n",
      "Epoch 81/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 149.3867 - val_loss: 151.1556\n",
      "Epoch 82/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 149.3321 - val_loss: 151.1050\n",
      "Epoch 83/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 149.3166 - val_loss: 150.9571\n",
      "Epoch 84/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 149.1971 - val_loss: 151.0635\n",
      "Epoch 85/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 149.1631 - val_loss: 150.9203\n",
      "Epoch 86/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 149.1304 - val_loss: 150.8225\n",
      "Epoch 87/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 149.0140 - val_loss: 150.7234\n",
      "Epoch 88/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 148.9879 - val_loss: 150.8112\n",
      "Epoch 89/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 148.9367 - val_loss: 150.6033\n",
      "Epoch 90/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 148.8487 - val_loss: 150.6791\n",
      "Epoch 91/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 148.8374 - val_loss: 150.9691\n",
      "Epoch 92/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 148.8277 - val_loss: 150.6869\n",
      "Epoch 93/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 148.7040 - val_loss: 150.4301\n",
      "Epoch 94/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 148.6555 - val_loss: 150.5223\n",
      "Epoch 95/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 148.5443 - val_loss: 150.4278\n",
      "Epoch 96/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 148.4562 - val_loss: 150.3092\n",
      "Epoch 97/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 148.5266 - val_loss: 150.2220\n",
      "Epoch 98/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 148.4048 - val_loss: 150.1569\n",
      "Epoch 99/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 148.3152 - val_loss: 150.2149\n",
      "Epoch 100/100\n",
      "212/212 [==============================] - 2s 9ms/step - loss: 148.2744 - val_loss: 150.3042\n",
      "0.5079874500643138\n",
      "[0.93245367 0.15897215 0.94562125 0.81971376 0.6915651  0.81099342\n",
      " 0.92821946 0.58666749 0.76461981 0.50798745]\n"
     ]
    }
   ],
   "source": [
    "evals = np.zeros((10))\n",
    "for i in range(10):\n",
    "    print(i)\n",
    "    # Evaluate each method 30 times\n",
    "    model = create_model()\n",
    "    model = fit_model(model, x_train, y_train, x_test, y_test, normal=i, verbose=1, caseii=True)\n",
    "\n",
    "    x = np.copy( x_test )\n",
    "    y = y_test\n",
    "    labels = np.copy( y )\n",
    "    labels[ y != i ] = 0\n",
    "    labels[ y == i ] = 1\n",
    "\n",
    "    xhat = model.predict(x)\n",
    "\n",
    "    x = x.reshape(len(x), 28*28)\n",
    "    xhat = xhat.reshape(len(xhat), 28*28)\n",
    "\n",
    "    err  = np.sum(np.abs(x-xhat), axis=1)\n",
    "    # Max-Min normalize the error\n",
    "    err /= np.max(err)\n",
    "    # Compute AUC\n",
    "    AUC = roc_auc_score(labels, err)\n",
    "    evals[i] = AUC\n",
    "    print(AUC)\n",
    "\n",
    "print(evals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CASE 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 250.7340 - val_loss: 195.5419\n",
      "Epoch 2/100\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 189.7135 - val_loss: 184.8431\n",
      "Epoch 3/100\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 182.4160 - val_loss: 178.1895\n",
      "Epoch 4/100\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 174.4519 - val_loss: 171.0659\n",
      "Epoch 5/100\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 170.1367 - val_loss: 168.6267\n",
      "Epoch 6/100\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 168.2594 - val_loss: 167.1134\n",
      "Epoch 7/100\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 166.9343 - val_loss: 165.9845\n",
      "Epoch 8/100\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 165.8093 - val_loss: 165.0377\n",
      "Epoch 9/100\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 164.7623 - val_loss: 164.3650\n",
      "Epoch 10/100\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 163.9003 - val_loss: 163.2638\n",
      "Epoch 11/100\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 163.0368 - val_loss: 162.6116\n",
      "Epoch 12/100\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 162.2930 - val_loss: 162.0937\n",
      "Epoch 13/100\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 161.4852 - val_loss: 161.1680\n",
      "Epoch 14/100\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 160.7470 - val_loss: 160.5355\n",
      "Epoch 15/100\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 160.1004 - val_loss: 160.0436\n",
      "Epoch 16/100\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 159.5175 - val_loss: 159.5462\n",
      "Epoch 17/100\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 158.9433 - val_loss: 159.0871\n",
      "Epoch 18/100\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 158.3693 - val_loss: 158.4216\n",
      "Epoch 19/100\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 157.8955 - val_loss: 157.9765\n",
      "Epoch 20/100\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 157.4152 - val_loss: 157.5041\n",
      "Epoch 21/100\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 156.9258 - val_loss: 156.9784\n",
      "Epoch 22/100\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 156.5045 - val_loss: 156.6222\n",
      "Epoch 23/100\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 156.0863 - val_loss: 156.1790\n",
      "Epoch 24/100\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 155.7290 - val_loss: 155.8965\n",
      "Epoch 25/100\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 155.3724 - val_loss: 155.6469\n",
      "Epoch 26/100\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 155.0398 - val_loss: 155.3022\n",
      "Epoch 27/100\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 154.7476 - val_loss: 155.0763\n",
      "Epoch 28/100\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 154.4398 - val_loss: 154.7539\n",
      "Epoch 29/100\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 154.1349 - val_loss: 154.5355\n",
      "Epoch 30/100\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 153.8849 - val_loss: 154.1835\n",
      "Epoch 31/100\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 153.6042 - val_loss: 153.9345\n",
      "Epoch 32/100\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 153.3097 - val_loss: 153.7543\n",
      "Epoch 33/100\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 153.0782 - val_loss: 153.4340\n",
      "Epoch 34/100\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 152.8464 - val_loss: 153.3555\n",
      "Epoch 35/100\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 152.6175 - val_loss: 153.0887\n",
      "Epoch 36/100\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 152.3893 - val_loss: 152.7860\n",
      "Epoch 37/100\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 152.1994 - val_loss: 152.5760\n",
      "Epoch 38/100\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 151.9666 - val_loss: 152.4602\n",
      "Epoch 39/100\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 151.7836 - val_loss: 152.2479\n",
      "Epoch 40/100\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 151.5661 - val_loss: 151.9703\n",
      "Epoch 41/100\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 151.3581 - val_loss: 151.7425\n",
      "Epoch 42/100\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 151.1654 - val_loss: 151.7264\n",
      "Epoch 43/100\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 150.9634 - val_loss: 151.4151\n",
      "Epoch 44/100\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 150.7882 - val_loss: 151.3021\n",
      "Epoch 45/100\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 150.6258 - val_loss: 151.1257\n",
      "Epoch 46/100\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 150.4710 - val_loss: 151.1235\n",
      "Epoch 47/100\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 150.3047 - val_loss: 150.8636\n",
      "Epoch 48/100\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 150.1958 - val_loss: 150.7215\n",
      "Epoch 49/100\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 150.0527 - val_loss: 150.6493\n",
      "Epoch 50/100\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 149.9294 - val_loss: 150.5077\n",
      "Epoch 51/100\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 149.7597 - val_loss: 150.5133\n",
      "Epoch 52/100\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 149.6375 - val_loss: 150.2496\n",
      "Epoch 53/100\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 149.5377 - val_loss: 150.0646\n",
      "Epoch 54/100\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 149.4193 - val_loss: 150.0749\n",
      "Epoch 55/100\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 149.3171 - val_loss: 150.0609\n",
      "Epoch 56/100\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 149.2155 - val_loss: 149.9786\n",
      "Epoch 57/100\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 149.0872 - val_loss: 149.8094\n",
      "Epoch 58/100\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 148.9765 - val_loss: 149.7647\n",
      "Epoch 59/100\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 148.9322 - val_loss: 149.7695\n",
      "Epoch 60/100\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 148.7931 - val_loss: 149.7188\n",
      "Epoch 61/100\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 148.6978 - val_loss: 149.3867\n",
      "Epoch 62/100\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 148.5630 - val_loss: 149.6314\n",
      "Epoch 63/100\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 148.5182 - val_loss: 149.3841\n",
      "Epoch 64/100\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 148.4745 - val_loss: 149.3623\n",
      "Epoch 65/100\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 148.3783 - val_loss: 149.2253\n",
      "Epoch 66/100\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 148.2831 - val_loss: 149.3126\n",
      "Epoch 67/100\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 148.2193 - val_loss: 149.1496\n",
      "Epoch 68/100\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 148.1130 - val_loss: 149.1872\n",
      "Epoch 69/100\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 148.0729 - val_loss: 149.0160\n",
      "Epoch 70/100\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 147.9471 - val_loss: 149.0007\n",
      "Epoch 71/100\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 147.8976 - val_loss: 148.8726\n",
      "Epoch 72/100\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 147.8506 - val_loss: 148.8178\n",
      "Epoch 73/100\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 147.7975 - val_loss: 148.7347\n",
      "Epoch 74/100\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 147.7453 - val_loss: 148.7997\n",
      "Epoch 75/100\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 147.6370 - val_loss: 148.6509\n",
      "Epoch 76/100\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 147.5951 - val_loss: 148.6093\n",
      "Epoch 77/100\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 147.5220 - val_loss: 148.7422\n",
      "Epoch 78/100\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 147.4516 - val_loss: 148.5474\n",
      "Epoch 79/100\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 147.4003 - val_loss: 148.5476\n",
      "Epoch 80/100\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 147.3627 - val_loss: 148.3516\n",
      "Epoch 81/100\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 147.2662 - val_loss: 148.3890\n",
      "Epoch 82/100\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 147.2453 - val_loss: 148.4754\n",
      "Epoch 83/100\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 147.1711 - val_loss: 148.3307\n",
      "Epoch 84/100\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 147.1214 - val_loss: 148.2203\n",
      "Epoch 85/100\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 147.0879 - val_loss: 148.2565\n",
      "Epoch 86/100\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 146.9956 - val_loss: 148.5576\n",
      "Epoch 87/100\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 146.9645 - val_loss: 148.1637\n",
      "Epoch 88/100\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 146.9389 - val_loss: 148.1636\n",
      "Epoch 89/100\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 146.8582 - val_loss: 148.2889\n",
      "Epoch 90/100\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 146.7945 - val_loss: 148.1700\n",
      "Epoch 91/100\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 146.7472 - val_loss: 148.1279\n",
      "Epoch 92/100\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 146.6767 - val_loss: 147.9715\n",
      "Epoch 93/100\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 146.6871 - val_loss: 147.9884\n",
      "Epoch 94/100\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 146.6380 - val_loss: 148.0394\n",
      "Epoch 95/100\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 146.5268 - val_loss: 147.7514\n",
      "Epoch 96/100\n",
      "235/235 [==============================] - 5s 23ms/step - loss: 146.4966 - val_loss: 147.7662\n",
      "Epoch 97/100\n",
      "235/235 [==============================] - 6s 26ms/step - loss: 146.4527 - val_loss: 147.8143\n",
      "Epoch 98/100\n",
      "235/235 [==============================] - 6s 26ms/step - loss: 146.4466 - val_loss: 147.8689\n",
      "Epoch 99/100\n",
      "235/235 [==============================] - 7s 28ms/step - loss: 146.3803 - val_loss: 147.8442\n",
      "Epoch 100/100\n",
      "235/235 [==============================] - 6s 27ms/step - loss: 146.3013 - val_loss: 147.8149\n",
      "0.97141728\n"
     ]
    }
   ],
   "source": [
    "# Evaluate each method 30 times\n",
    "model = create_model()\n",
    "model = fit_model(model, x_train, y_train, x_test, y_test, verbose=1, caseiii=True)\n",
    "\n",
    "x = np.copy( x_test )\n",
    "x[5000:] = f_x_test[:5000]\n",
    "\n",
    "labels = np.zeros( y_test.shape )\n",
    "labels[5000:] = 1\n",
    "\n",
    "xhat = model.predict(x)\n",
    "\n",
    "x = x.reshape(len(x), 28*28)\n",
    "xhat = xhat.reshape(len(xhat), 28*28)\n",
    "\n",
    "err  = np.sum(np.abs(x-xhat), axis=1)\n",
    "# Max-Min normalize the error\n",
    "err /= np.max(err)\n",
    "# Compute AUC\n",
    "AUC = roc_auc_score(labels, err)\n",
    "print(AUC)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
